#Operating_Systems #OS_Processes 
## Зачем процессам взаимодействовать?
### Основные причины взаимодействия процессов
Процессы в операционной системе не всегда работают изолированно. Существует несколько важных причин, по которым процессам необходимо взаимодействовать друг с другом:
#### 1) Повышение скорости работы (Performance Enhancement)
- Когда один процесс ожидает наступления некоторого события (например, окончания операции ввода-вывода), другие процессы в это время могут заниматься полезной работой, направленной на решение общей задачи
- В **многопроцессорных вычислительных системах** программа может быть разделена на отдельные части, каждая из которых будет исполняться на отдельном процессоре
- Это позволяет эффективно использовать все доступные вычислительные ресурсы системы
- Параллельное выполнение задач существенно сокращает общее время выполнения
#### 2) Совместное использование данных (Data Sharing)
- Различные процессы могут работать с одной и той же информацией
- Процессы могут иметь доступ к общим ресурсам и данным
- Это позволяет избежать дублирования информации в памяти
- Обеспечивает согласованность данных между процессами
#### 3) Модульная конструкция системы (Modularity)
- Типичным примером служит **микроядерный способ построения операционной системы**
- Различные части ОС представляют собой отдельные процессы
- Процессы общаются путем передачи сообщений друг другу
- Такой подход упрощает разработку, отладку и поддержку системы
- Позволяет легко добавлять или заменять модули без изменения всей системы
#### 4) Удобство для пользователя (User Convenience)
- Пользователь может одновременно редактировать и отлаживать программу
- В этой ситуации процессы редактора и отладчика должны уметь взаимодействовать друг с другом
- Возможность работы с несколькими приложениями одновременно
- Обмен данными между приложениями (например, копирование из одного приложения в другое)
### Кооперативные и независимые процессы
**Важное замечание:** Процессы не могут взаимодействовать, не общаясь. Общение процессов обычно приводит к изменению их поведения в зависимости от полученной информации.

**Независимые процессы:**
- Если деятельность процессов остается неизменной при любой принятой ими информации, то это означает, что процессы фактически не взаимодействуют
- Не оказывают друг на друга никакого воздействия
- Ничего не знают о взаимном сосуществовании в вычислительной системе

**Кооперативные (взаимодействующие) процессы:**
- Влияют на поведение друг друга путем обмена информацией
- Координируют свои действия для достижения общей цели
- Могут совместно использовать ресурсы и данные
---
## Виды взаимодействия процессов
### 1. Конкуренция (Competition)
- Процессы конкурируют при доступе к ограниченным ресурсам системы
- Ресурсы могут включать: процессорное время, память, устройства ввода-вывода
- Операционная система должна обеспечивать справедливое распределение ресурсов
- Требуются механизмы синхронизации для предотвращения конфликтов

### 2. Кооперация (Cooperation)
- Процессы совместно работают над решением одной задачи
- Обмениваются информацией для координации действий
- Могут разделять общие данные и ресурсы
- Требуют механизмов синхронизации и коммуникации
---
## Категории обмена информацией
Процессы могут взаимодействовать только посредством обмена информацией.

Существует три основных категории механизмов обмена информацией между процессами:
### 1) Сигнальный обмен (Signaling)
- Процессы могут посылать друг другу простые сигналы
- Сигналы обычно не несут большого объема информации
- Используются для уведомления о событиях
- **Важность правильной реакции:** Неправильная реакция на сигнал или его игнорирование могут привести к трагическим последствиям

**Характеристики:**
- Минимальный объем передаваемой информации
- Быстрая передача
- Простота реализации
- Ограниченное влияние на поведение процесса
### 2) Каналы (Channels / Message Passing)
- Общение процессов происходит через линии связи, предоставленные операционной системой
- Напоминает общение людей по телефону
- Процессы могут посылать и получать сообщения
- С увеличением количества информации увеличивается возможность влияния на поведение другого процесса

**Характеристики:**
- Средний объем передаваемой информации
- Структурированный обмен данными
- Требует системных вызовов для отправки и получения сообщений
- Безопасный способ обмена данными между процессами

### 3) Разделяемая память (Shared Memory)
- Два или более процессов могут совместно использовать некоторую область адресного пространства
- Созданием разделяемой памяти управляет операционная система
- Обеспечивает максимальную возможность обмена информацией

**Преимущества:**
- Самый быстрый способ взаимодействия процессов в одной вычислительной системе
- Использование разделяемой памяти для передачи/получения информации осуществляется с помощью средств обычных языков программирования
- Не требуются специальные системные вызовы для каждой операции чтения/записи
- Высокая производительность

**Недостатки и предостережения:**
- Требует повышенной осторожности при использовании
- Максимальное влияние на поведение другого процесса
- Необходимы механизмы синхронизации для предотвращения конфликтов

**Сравнение с другими методами:**
- Сигнальным и канальным средствам коммуникации для передачи информации необходимы специальные системные вызовы
- Разделяемая память работает напрямую через операции чтения/записи в память
---
## Характеристики логической организации связи
### Установка связи
##### Нужна ли инициализация связи?
- В некоторых системах требуется предварительная инициализация связи между процессами
- В других системах связь может быть установлена динамически во время выполнения
- Требования к инициализации зависят от используемого механизма обмена

### Адресация
Если процессы должны обмениваться информацией, необходимо определить, как они будут находить друг друга.
#### Прямая связь (Direct Communication)
- Процессы непосредственно обращаются друг к другу с указанием идентификаторов
- Может быть **симметричной** и **асимметричной**

**Симметричная прямая связь:**
- Оба процесса явно указывают идентификаторы друг друга
- Пример: процесс P отправляет сообщение процессу Q, указывая его ID

**Асимметричная прямая связь:**
- Только один процесс указывает идентификатор другого
- Второй процесс может принимать сообщения от любых процессов

#### Непрямая (косвенная) связь (Indirect Communication)
- Существует **промежуточный объект** (mailbox, port, канал)
- Информация помещается в этот объект одним процессом
- Другой процесс может получить информацию из этого объекта
- Процессы не обращаются напрямую друг к другу

**Преимущества непрямой связи:**
- Большая гибкость
- Один объект может использоваться несколькими процессами
- Процессы могут не знать о существовании друг друга

### Информационная валентность
**Информационная валентность** определяет количество отправителей и получателей в процессе обмена информацией.
#### Одноадресный обмен (Uni-cast)
- Один отправитель и один получатель
- Прямой обмен между двумя процессами
#### Многоадресный обмен (Multi-cast)
- Один отправитель и несколько получателей
- Процесс отправляет сообщение группе процессов
#### Широковещательный обмен (Broadcast)
- Один отправитель и все процессы в системе
- Сообщение доставляется всем процессам

### Направление обмена
#### Однонаправленный обмен (Simplex)
- Информация передается только в одном направлении
- От отправителя к получателю
#### Полудуплексный обмен (Half-Duplex)
- Информация может передаваться в обоих направлениях
- Но не одновременно
#### Полнодуплексный обмен (Full-Duplex)
- Информация может передаваться в разных направлениях одновременно
- Наиболее гибкий способ обмена
- Позволяет эффективную двустороннюю коммуникацию

### Особенности средств связи
**Буферизация**
- Средства связи могут использовать буферы для хранения данных перед их передачей
- Буферизация помогает сгладить различия в скорости передачи между отправителем и получателем
- Может быть реализована на уровне операционной системы или приложений

Типы буферов:
- **Фиксированный размер:** Буфер имеет заранее определенный размер
- **Переменный размер:** Буфер может динамически изменять свой размер в зависимости от потребностей
- **Нулевой размер:** Нет буфера, данные передаются напрямую
- **Очередь сообщений:** Сообщения помещаются в очередь и обрабатываются по мере поступления
- **Кольцевой буфер:** Используется для циклического хранения данных, позволяя эффективно использовать память
### Структуризация информации
- Средства связи могут поддерживать различные форматы и структуры данных
- Это может включать простые байтовые потоки, структурированные сообщения или сложные объекты
- Структуризация помогает упростить обработку и интерпретацию данных
### Надежность связи
1) **Не происходит потери информации**.
2) **Не происходит повреждения информации**.
3) **Не появляется лишней информации**.
4) **Не нарушается порядок данных в процессе обмена**.
### Завершение обмена
К каким последствиям приводит завершение процесса во время обмена информацией?
**Ответственность за обработку:**
- **Операционная система:** ОС может взять на себя обработку незавершенного обмена
- **Процесс:** Процесс сам должен корректно завершить все операции обмена
- **Совместная ответственность:** И процесс, и операционная система участвуют в корректном завершении

**Возможные проблемы:**
- Потеря данных
- Блокировка других процессов, ожидающих сообщения
- Утечка ресурсов (незакрытые каналы, неосвобожденная разделяемая память)
---
## Проблемы при взаимодействии процессов
### 1) Занятое ожидание (Busy Wait / Busy Waiting)
**Определение:** Процесс находится в цикле, постоянно проверяя условие, вместо того чтобы быть заблокированным и отданным в очередь ожидания.

**Проблемы:**
- Напрасная трата процессорного времени
- Процесс вращается в пустом цикле, не выполняя полезной работы
- Особенно критично в системах с ограниченными ресурсами
- Снижает общую производительность системы

**Пример:**
```c
while (condition_not_met) {
    // Пустой цикл - процессор работает вхолостую
}
```

### 2) Недетерминированность результата
**Определение:** Зависимость результата не только от алгоритма и входных данных, но и от порядка выполнения процессов.

**Причины:**
- Отсутствие синхронизации при доступе к общим ресурсам
- Непредсказуемый порядок выполнения процессов
- Случайное чередование операций разных процессов

**Последствия:**
- Невозможность воспроизвести ошибку
- Сложность отладки
- Ненадежность системы

### 3) Инверсия приоритетов (Priority Inversion)
**Определение:** Ситуация, когда процесс с высоким приоритетом вынужден ждать завершения процесса с низким приоритетом.

**Типичный сценарий:**
1. Процесс L (низкий приоритет) входит в критическую секцию
2. Процесс H (высокий приоритет) готов к выполнению и вытесняет L
3. H пытается войти в ту же критическую секцию, но не может (L в ней)
4. H вращается в цикле ожидания (busy wait)
5. L не получает процессорное время, чтобы выйти из критической секции
6. Возникает тупиковая ситуация

**Решение:** Использование специальных протоколов наследования приоритетов или механизмов блокировки без busy wait.

### 4) Голодание (Starvation)
**Определение:** Ситуация, когда процесс не может получить доступ к необходимым ресурсам в течение неопределенно долгого времени из-за того, что другие процессы постоянно получают приоритет. 

**Причины:**
- Несправедливые алгоритмы планирования
- Наличие процессов с более высоким приоритетом
- Неправильная настройка системы приоритетов
- Постоянный поток высокоприоритетных задач

**Последствия:**
- Процесс может никогда не завершиться
- Деградация производительности для определенных задач
- Нарушение гарантий реального времени
- Возможна полная неработоспособность низкоприоритетных сервисов

**Пример сценария:**
1. Процесс A (низкий приоритет) ожидает доступа к принтеру
2. Постоянно поступают задачи с более высоким приоритетом (B, C, D...)
3. Процесс A постоянно откладывается
4. A может ждать бесконечно долго

### 5) Тупик / Взаимная блокировка (Deadlock)
**Определение:** Ситуация, когда два или более процессов взаимно блокируют друг друга, каждый ожидая ресурс, занятый другим процессом. 

**Четыре условия возникновения тупика (условия Коффмана):**
1. **Взаимное исключение** - ресурс может использоваться только одним процессом
2. **Удержание и ожидание** - процесс удерживает ресурс и ждет другой
3. **Отсутствие принудительного освобождения** - ресурс нельзя отобрать принудительно
4. **Циклическое ожидание** - существует замкнутая цепочка процессов

**Классический пример:**
```c
// Процесс P1:
lock(resource_A);
// ...  выполняется работа ... 
lock(resource_B);  // Ждет B, которым владеет P2
// ... критическая секция ...
unlock(resource_B);
unlock(resource_A);

// Процесс P2:
lock(resource_B);
// ... выполняется работа ...
lock(resource_A);  // Ждет A, которым владеет P1
// ... критическая секция ... 
unlock(resource_A);
unlock(resource_B);
```

**Последствия:**
- Полная остановка участвующих процессов
- Блокировка системных ресурсов
- Необходимость внешнего вмешательства для разрешения

**Методы борьбы:**
- **Предотвращение** - нарушение хотя бы одного из условий Коффмана
- **Избежание** - алгоритм банкира (Banker's algorithm)
- **Обнаружение и восстановление** - периодическая проверка и принудительное прерывание
- **Игнорирование** - алгоритм страуса (используется в некоторых ОС)

### 6) Состояние гонки / Эффект гонок (Race Condition)
**Определение:** Ситуация, когда результат выполнения программы зависит от относительного времени или порядка выполнения нескольких процессов или потоков, обращающихся к общим ресурсам. 

**Причины:**
- Одновременный доступ к разделяемым данным
- Отсутствие или неправильная синхронизация
- Некорректное использование механизмов блокировки
- Атомарные операции разбиты на несколько неатомарных

**Классический пример:**
```c
// Общая переменная
int counter = 0;

// Поток 1:
void thread1() {
    for (int i = 0; i < 1000; i++) {
        counter++;  // НЕ атомарная операция! 
        // Реально:  temp = counter; temp = temp + 1; counter = temp;
    }
}

// Поток 2:
void thread2() {
    for (int i = 0; i < 1000; i++) {
        counter++;  // НЕ атомарная операция!
    }
}

// Ожидаемый результат:  counter = 2000
// Реальный результат: непредсказуем (например, 1337, 1856, и т.д.)
```

**Пошаговый сценарий возникновения:**
1. Поток 1 читает counter = 5
2. Поток 1 вычисляет 5 + 1 = 6
3. **Переключение контекста на Поток 2**
4. Поток 2 читает counter = 5 (старое значение!)
5. Поток 2 вычисляет 5 + 1 = 6
6. Поток 2 записывает counter = 6
7. **Переключение контекста на Поток 1**
8. Поток 1 записывает counter = 6
9. **Результат: потеряно одно инкрементирование!**

**Последствия:**
- Непредсказуемые результаты вычислений
- Повреждение данных
- Крайне сложная отладка (ошибка не воспроизводится стабильно)
- Потенциальные уязвимости безопасности (TOCTOU - Time Of Check, Time Of Use)

**Решения:**
- Использование мьютексов, семафоров, критических секций
- Атомарные операции
- Блокировки (locks)
- Транзакционная память
- Избегание разделяемого состояния (immutable data, message passing)

**Пример с защитой:**
```c
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
int counter = 0;

void thread_safe_increment() {
    pthread_mutex_lock(&mutex);
    counter++;  // Теперь это защищено
    pthread_mutex_unlock(&mutex);
}
```
---
## Даже при наличии надежной связи могут возникнуть проблемы
Даже если у нас установлена надежная связь между процессами, это не гарантирует отсутствие проблем при параллельном выполнении. Рассмотрим ключевые концепции.
### Чередование операций (Interleaving)
**Interleaving (чередование операций)** — это процесс, при котором операции из нескольких активностей выполняются в таком порядке, что их действия переплетаются.

**Активность** — это последовательность действий, направленных на достижение цели.

**Активности состоят из неделимых операций (атомарных операций)** — операций, которые выполняются как единое целое и не могут быть прерваны.

При псевдопараллельном (или параллельном) выполнении нескольких активностей возникает множество возможных последовательностей выполнения их неделимых операций.
#### Пример возможных последовательностей
Предположим, у нас есть две активности с операциями:
- Активность 1: операции a, b, c
- Активность 2: операции d, e, f

**Возможные последовательности выполнения:**
- a b c d e f
- a b d c e f
- a b d e c f
- a b d e f c
- a d b c e f
- ...
- d e f a b c

Видно то что **последовательность** инструкций **внутри каждой активности сохраняется**, но порядок между активностями может меняться.

Можно заметить что число возможных чередований операций двух активностей с m и n операциями соответственно равно числу сочетаний $C(m+n, n) = (m+n)! / (m! * n!)$.
#### Пример конкретного взаимодействия
Пусть у нас есть две активности P и Q, состоящие из двух атомарных операций каждая:

**Активность P:**
```
x = 1;
y = 2;
```

**Активность Q:**
```
x = 3;
y = 4;
```

**Вопрос:** Что мы получим в результате их псевдопараллельного выполнения, если переменные x и y являются общими для активностей?

**Возможные последовательности и результаты:**
1. **P полностью, затем Q:**
   ```
   x = 1; y = 2; x = 3; y = 4;
   Результат: (x=3, y=4)
   ```

2. **Q полностью, затем P:**
   ```
   x = 3; y = 4; x = 1; y = 2;
   Результат: (x=1, y=2)
   ```

3. **Чередование: P₁, Q₁, P₂, Q₂:**
   ```
   x = 1; x = 3; y = 2; y = 4;
   Результат: (x=3, y=4)
   ```

4. **Чередование: P₁, Q₁, Q₂, P₂:**
   ```
   x = 1; x = 3; y = 4; y = 2;
   Результат: (x=3, y=2)
   ```

5. **Чередование: Q₁, P₁, P₂, Q₂:**
   ```
   x = 3; x = 1; y = 2; y = 4;
   Результат: (x=1, y=4)
   ```

6. **Чередование: Q₁, P₁, Q₂, P₂:**
   ```
   x = 3; x = 1; y = 4; y = 2;
   Результат: (x=1, y=2)
   ```

**Вывод:** Легко видеть, что возможны **четыре разных набора значений** для пары (x, y): **(3, 4), (1, 2), (1, 4) и (3, 2)**.

---
## Детерминированность
### Определение детерминированности
**Набор активностей (например, программ) детерминирован**, если всякий раз при псевдопараллельном исполнении для одного и того же набора входных данных получается один и тот же результат.

**Важность:**
- Детерминированный набор активностей можно безбоязненно выполнять в режиме разделения времени
- Для недетерминированного набора такое исполнение нежелательно
- Детерминированность обеспечивает предсказуемость и надежность системы

### Наборы переменных
Для формального анализа детерминированности вводятся следующие понятия:

**Набор входных переменных программы R(P):**
- Объединение наборов входных переменных для всех ее (программных) неделимых действий
- Переменные, которые программа читает

**Набор выходных переменных программы W(P):**
- Объединение наборов выходных переменных для всех ее (программных) неделимых действий
- Переменные, в которые программа записывает значения
---
## Достаточные условия Бернстайна
Для двух программ (активностей) P и Q выполнение является детерминированным, если выполняются следующие условия:
### Условия Бернстайна:
1. **R(P) ∩ W(Q) = ∅**
   - Входные переменные P не пересекаются с выходными переменными Q
   - P не читает то, что записывает Q

2. **W(P) ∩ R(Q) = ∅**
   - Выходные переменные P не пересекаются с входными переменными Q
   - P не записывает то, что читает Q

3. **W(P) ∩ W(Q) = ∅**
   - Выходные переменные P не пересекаются с выходными переменными Q
   - P и Q не записывают в одни и те же переменные

**Тогда выполнение P и Q детерминировано.**
### Анализ условий Бернстайна
**Достоинства:**
- Формальный критерий детерминированности
- Легко проверяемые условия
- Гарантируют безопасное параллельное выполнение

**Недостатки:**
- Условия Бернстайна информативны, но слишком жестки
- По сути они требуют практически невзаимодействующих процессов
- На практике процессам часто необходимо:
	  - Совместно использовать информацию
	  - Обмениваться данными
	  - Работать с общими ресурсами

**Решение:**
Нам необходимо ограничить число возможных чередований атомарных операций, исключив некоторые чередования с помощью **механизмов синхронизации** выполнения программ, обеспечив тем самым **упорядоченный доступ** программ к некоторым ресурсам.

---
## Race Condition (Состояние гонки)
### Определение
**Race Condition (Состояние гонки, состояние состязания)** — ситуация, когда результат выполнения последовательности действий зависит не только от алгоритма и входных данных, но и от того, какие процессы выполнялись одновременно или псевдоодновременно.

Про недетерминированный набор программ (и активностей вообще) говорят, что он имеет race condition.

**Последствия:**
- Непредсказуемые результаты выполнения программы
- Ошибки, которые трудно воспроизвести
- Потеря или повреждение данных
- Нарушение целостности системы
- Сложность отладки и тестирования
### Пример отсутствия синхронизации
**Типичный сценарий:**
1. Процесс A читает значение переменной count = 5
2. Процесс B читает значение переменной count = 5
3. Процесс A увеличивает значение: count = 6
4. Процесс B увеличивает значение: count = 6
5. Процесс A записывает count = 6
6. Процесс B записывает count = 6

**Ожидаемый результат:** count = 7 (5 + 2 операции инкремента)
**Фактический результат:** count = 6 (одна операция была потеряна)

---
## Критическая секция (Critical Section)
### Определение
**Критическая секция** — участок кода программы, при выполнении которого может возникнуть эффект гонок.

Критическая секция обычно связана с:
- Доступом к общим данным
- Использованием разделяемых ресурсов
- Изменением общих переменных
- Операциями, которые должны выполняться атомарно

## Где необходима синхронизация ?
Синхронизация необходима:
1. **При прерываниях:**
   - Обработчики прерываний могут изменять общие данные
   - Основная программа может быть прервана в любой момент
   - Требуется защита критических участков от прерываний

2. **При блокировках:**
   - Процессы могут блокироваться в ожидании ресурсов
   - Необходимо корректно управлять состоянием блокировок
   - Избегать взаимоблокировок (deadlock)

3. **При обработке:**
   - Совместная обработка данных несколькими процессами
   - Операции, требующие эксклюзивного доступа
   - Транзакции, которые должны выполняться целиком

---
## Требования к алгоритмам синхронизации
Для корректной работы механизмов синхронизации должны выполняться следующие требования:
### 1) Программная реализация
**Задача должна быть решена чисто программным способом** на обычной машине, не имеющей специальных команд взаимоисключения.

При этом предполагается, что основные инструкции языка программирования (такие примитивные инструкции как load, store, test) выполняются атомарно.

### 2) Независимость от скорости и количества процессоров
Не должно существовать никаких предположений об относительных скоростях выполняющихся процессов или числе процессоров, на которых они выполняются.

**Важность:**
- Алгоритм должен работать корректно на любой системе
- Не должен зависеть от конкретной конфигурации оборудования
- Должен корректно работать при изменении нагрузки системы

### 3) Взаимное исключение (Mutual Exclusion)
**Если процесс $P_{i}$ исполняется в своем критическом участке, то не существует никаких других процессов, которые исполняются в своих критических секциях**, связанных с теми же общими данными или ресурсами.

**Суть:**
- В каждый момент времени только один процесс может находиться в критической секции
- Это фундаментальное требование для предотвращения race condition

### 4) Прогресс (Progress)
Процессы, которые находятся вне своих критических участков и не собираются входить в них, **не могут препятствовать** другим процессам входить в их собственные критические участки.

**Условие прогресса:**
- Если нет процессов в критических секциях
- И имеются процессы, желающие войти в них
- То **только те процессы, которые не исполняются в remainder section**, должны принимать решение о том, какой процесс войдет в свою критическую секцию
- Такое решение **не должно приниматься бесконечно долго**

**Что это означает:**
- Система не должна застревать в неопределенном состоянии
- Должен быть гарантирован прогресс выполнения
- Не должно быть бесконечного откладывания принятия решения

### 5) Ограниченное ожидание (Bounded Waiting)
Не должно возникать **бесконечного ожидания** для входа процесса в свой критический участок.

**Условие ограниченного ожидания:**
- От того момента, когда процесс запросил разрешение на вход в критическую секцию
- И до того момента, когда он это разрешение получил
- Другие процессы могут пройти через свои критические участки **лишь ограниченное число раз**

**Важность:**
- Предотвращает голодание (starvation) процессов
- Гарантирует справедливость (fairness)
- Обеспечивает предсказуемое время ожидания

#### Структура алгоритма
Алгоритм синхронизации реализуется в виде **входа и выхода из критической секции**:

```
while (some condition) {
    // ВХОД В КРИТИЧЕСКУЮ СЕКЦИЮ (пролог)
    entry_section();
    
    // КРИТИЧЕСКАЯ СЕКЦИЯ
    critical_section();
    
    // ВЫХОД ИЗ КРИТИЧЕСКОЙ СЕКЦИИ (эпилог)
    exit_section();
    
    // ОСТАЛЬНАЯ ЧАСТЬ ПРОГРАММЫ
    remainder_section();
}
```

Описание алгоритма синхронизации означает описание способа организации **пролога и эпилога** для критической секции.

---

## Алгоритмы синхронизации
### 1. Запрет прерываний
#### Идея алгоритма
```c
while (some condition) {
    // Запретить все прерывания
    disable_interrupts();
    
    // Критическая секция
    critical_section();
    
    // Разрешить все прерывания
    enable_interrupts();
    
    // Остальная часть
    remainder_section();
}
```
#### Анализ
**Почему этот способ нельзя использовать широко?**
1. **Опасность для системы:**
   - Процесс получает полный контроль над системой
   - Может не включить прерывания обратно (намеренно или из-за ошибки)
   - Система может "зависнуть"

2. **Проблемы в многопроцессорных системах:**
   - Запрет прерываний действует только на текущем процессоре
   - На других процессорах процессы могут входить в критическую секцию
   - Не обеспечивает mutual exclusion в многопроцессорных системах

3. **Влияние на производительность:**
   - Прерывания не обрабатываются во время критической секции
   - Может привести к потере важных событий
   - Увеличивает время отклика системы

4. **Безопасность:**
   - Пользовательские программы не должны иметь права запрещать прерывания
   - Это системная привилегия

**Вывод:** Подходит только для внутренних нужд ядра ОС и только для очень коротких критических секций.

---
### 2. Переменная-замок (Lock Variable)
#### Идея алгоритма
```c
shared int lock = 0;  // 0 = свободно, 1 = занято

while (some condition) {
    // Вход в критическую секцию
    while (lock);  // Ждем, пока lock == 1
    lock = 1;      // Занимаем критическую секцию
    
    // Критическая секция
    critical_section();
    
    // Выход из критической секции
    lock = 0;      // Освобождаем критическую секцию
    
    // Остальная часть
    remainder_section();
}
```
#### Недостатки
**Проблема:** Действие `while(lock); lock = 1;` **не является атомарным**.

**Сценарий возникновения проблемы:**
1. Процесс P₀ протестировал значение переменной lock (lock == 0)
2. P₀ принял решение двигаться дальше
3. **В этот момент**, еще до присваивания `lock = 1`, планировщик передал управление процессу P₁
4. P₁ тоже изучает содержимое переменной lock (все еще lock == 0)
5. P₁ тоже принимает решение войти в критический участок
6. **Результат:** Оба процесса в критической секции одновременно!

**Какое требование нарушено?**
- Нарушено требование **взаимного исключения (mutual exclusion)**
- Возможна ситуация одновременного выполнения критических секций

**Вывод:** Алгоритм некорректен и не может использоваться.

---
### 3) Строгое чередование (Strict Alteration)
#### Идея алгоритма
```c
shared int turn = 0;  // Чья очередь: 0 = P0, 1 = P1

// Для процесса Pi (i = 0 или 1):
while (some condition) {
    // Вход в критическую секцию
    while (turn != i);  // Ждем своей очереди
    
    // Критическая секция
    critical_section();
    
    // Выход из критической секции
    turn = 1 - i;  // Передаем очередь другому процессу
    
    // Остальная часть
    remainder_section();
}
```
#### Анализ
**Преимущества:**
- Взаимоисключение гарантируется ✓
- Процессы входят в критическую секцию строго по очереди: P₀, P₁, P₀, P₁, ...
- Простота реализации

**Недостатки:**
**Нарушение условия прогресса:**
- Если значение `turn` равно 1, и процесс P₀ готов войти в критический участок, он **не может** сделать этого
- Даже если процесс P₁ находится в remainder_section и не собирается входить в критическую секцию
- Процесс P₀ **вынужден ждать**, пока P₁ войдет и выйдет из критической секции

**Пример проблемы:**
1. P₀ вошел и вышел из критической секции, установил turn = 1
2. P₁ не нуждается в критической секции и работает в remainder_section
3. P₀ снова нуждается в критической секции, но не может войти (turn != 0)
4. P₀ вынужден ждать, хотя никто не находится в критической секции

**Вывод:** Алгоритм нарушает условие прогресса и неэффективен.

---
### 4) Флаги готовности
#### Идея алгоритма
Недостаток предыдущего алгоритма заключается в том, что процессы ничего не знают о состоянии друг друга в текущий момент времени. Давайте попробуем исправить эту ситуацию.

**Решение:** Два процесса имеют разделяемый массив флагов готовности:
- Когда i-й процесс готов войти в критическую секцию, он присваивает `ready[i] = 1`
- После выхода из критической секции он сбрасывает `ready[i] = 0`
- Процесс не входит в критическую секцию, если другой процесс уже готов ко входу

```c
shared int ready[2] = {0, 0};  // Флаги готовности

// Для процесса Pi (i = 0 или 1):
while (some condition) {
    // Вход в критическую секцию
    ready[i] = 1;           // Объявляем о своей готовности
    while (ready[1-i]);     // Ждем, пока другой не будет готов
    
    // Критическая секция
    critical_section();
    
    // Выход из критической секции
    ready[i] = 0;           // Снимаем флаг готовности
    
    // Остальная часть
    remainder_section();
}
```

#### Недостатки
**Проблема:** Возможен **дедлок (тупиковая ситуация)**.

**Сценарий возникновения дедлока:**
1. Процессы практически одновременно подошли к выполнению пролога
2. Процесс P₀ выполнил `ready[0] = 1`
3. Планировщик передал процессор от P₀ процессу P₁
4. Процесс P₁ выполнил `ready[1] = 1`
5. Теперь оба процесса в цикле `while (ready[1-i])`
6. **Результат:** Оба процесса бесконечно долго ждут друг друга на входе в критическую секцию

**Вывод:** Алгоритм может привести к deadlock и не может использоваться.

---
### 5) Алгоритм Петерсона (Peterson's Algorithm, 1981)
#### Идея алгоритма
Объединяет идеи алгоритмов строгого чередования и флагов готовности.
```c
shared int ready[2] = {0, 0};  // Флаги готовности
shared int turn;                // Чья очередь

// Для процесса Pi (i = 0 или 1):
while (some condition) {
    // Вход в критическую секцию
    ready[i] = 1;                          // Объявляем о готовности
    turn = 1 - i;                          // Предлагаем очередь другому
    while (ready[1-i] && turn == 1-i);    // Ждем своей очереди
    
    // Критическая секция
    critical_section();
    
    // Выход из критической секции
    ready[i] = 0;                          // Снимаем флаг готовности
    
    // Остальная часть
    remainder_section();
}
```

#### Анализ алгоритма
**Как это работает:**

При исполнении пролога критической секции процесс Pi:
1. **Объявляет о своей готовности** выполнить критический участок
2. **Одновременно предлагает другому процессу** приступить к его выполнению

**Если оба процесса подошли к прологу практически одновременно:**
1. Оба объявят о своей готовности: `ready[0] = 1`, `ready[1] = 1`
2. Оба предложат выполняться друг другу
3. Но одно из предложений всегда последует после другого
4. **Работу в критическом участке продолжит процесс, которому было сделано последнее предложение**

**Пример:**
- P₀ выполнил `ready[0] = 1; turn = 1;`
- P₁ выполнил `ready[1] = 1; turn = 0;`
- Последнее присваивание: `turn = 0`
- P₁ видит `ready[0] == 1 && turn == 0`, условие ложно → P₁ ждет
- P₀ видит `ready[1] == 1 && turn == 1`, условие ложно → P₀ входит в КС

#### Проверка требований
✓ **Взаимное исключение:** Гарантируется
✓ **Прогресс:** Обеспечивается
✓ **Ограниченное ожидание:** Соблюдается
✓ **Независимость от скорости процессов:** Да

**Вывод:** Алгоритм Петерсона корректен и решает проблему критической секции для двух процессов!

---
### 6) Алгоритм булочной (Bakery Algorithm)
#### Мотивация

Алгоритм Петерсона дает решение для **двух процессов**. Необходим алгоритм для **n взаимодействующих процессов**.

#### Идея алгоритма
Алгоритм имитирует систему обслуживания в булочной с талончиками:

**Принцип работы:**
- Каждый вновь прибывающий клиент (процесс) получает талончик на обслуживание с номером
- Клиент с **наименьшим номером** на талончике обслуживается следующим
- Из-за неатомарности операции вычисления следующего номера возможны **одинаковые номера**
- При равенстве номеров первым обслуживается клиент с **меньшим значением имени** (идентификатора процесса)

#### Структуры данных
```c
shared enum {false, true} choosing[n];  // Процесс выбирает номер
shared int number[n];                    // Номер талончика процесса
```

**Инициализация:**
- `choosing[i] = false` для всех i
- `number[i] = 0` для всех i

**Обозначение:**
- `max(a₀, a₁, ..., aₙ)` — это число k такое, что k ≥ aᵢ для всех i = 0, ..., n
- `(a, b) < (c, d)` означает `(a < c) || (a == c && b < d)` — лексикографическое сравнение пар

#### Код алгоритма
```c
// Для процесса Pi:
while (some condition) {
    // Вход в критическую секцию
    
    // Получение номера талончика
    choosing[i] = true;
    number[i] = max(number[0], ..., number[n-1]) + 1;
    choosing[i] = false;
    
    // Ожидание своей очереди
    for (j = 0; j < n; j++) {
        // Ждем, пока процесс j выбирает номер
        while (choosing[j]);
        
        // Ждем, пока:
        // - процесс j не в критической секции (number[j] == 0), ИЛИ
        // - наша очередь раньше (меньший номер или меньший ID)
        while (number[j] != 0 && (number[j], j) < (number[i], i));
    }
    
    // Критическая секция
    critical_section();
    
    // Выход из критической секции
    number[i] = 0;  // Освобождаем талончик
    
    // Остальная часть
    remainder_section();
}
```

#### Анализ алгоритма
**Преимущества:**
✓ Корректно работает для n процессов
✓ Удовлетворяет всем требованиям синхронизации
✓ Гарантирует взаимное исключение
✓ Обеспечивает прогресс
✓ Справедливость: процессы обслуживаются в порядке запросов

**Как это работает:**
1. Процесс получает номер на 1 больше максимального текущего
2. Ждет, пока все процессы с меньшими номерами (или меньшими ID при равных номерах) завершат работу
3. При равенстве номеров приоритет отдается процессу с меньшим идентификатором

**Особенности:**
- Возможны одинаковые номера у разных процессов (из-за неатомарности вычисления max)
- Это не проблема благодаря лексикографическому сравнению пар (номер, ID)

---
## Недостатки программных алгоритмов синхронизации

### Общие недостатки
Рассмотренные алгоритмы, хотя и являются корректными, имеют существенные практические недостатки:

#### 1. Сложность реализации
- Алгоритмы достаточно громоздки
- Не обладают элегантностью
- Сложны для понимания и отладки
- Легко допустить ошибку при реализации

#### 2. Занятое ожидание (Busy Waiting)
**Главная проблема:** Процедура ожидания входа в критический участок включает в себя достаточно длительное вращение процесса в пустом цикле.

**Последствия:**
- Процесс вхолостую пожирает драгоценное время процессора
- Снижается общая производительность системы
- Особенно критично для систем с большим числом процессов
- Энергетически неэффективно (важно для мобильных устройств)

**Пример busy waiting:**
```c
while (condition) {
    // Пустой цикл - процессор работает, но ничего не делает полезного
}
```

### Инверсия приоритетов
#### Описание проблемы
**Сценарий:**
- В системе два взаимодействующих процесса:
  - **H** — с высоким приоритетом
  - **L** — с низким приоритетом
- Планировщик устроен так, что процесс с высоким приоритетом **вытесняет** низкоприоритетный процесс всякий раз, когда он готов к исполнению
- H занимает процессор на все время своего CPU burst

#### Тупиковая ситуация
**Последовательность событий:**
1. Процесс L находится в своей критической секции
2. Процесс H, получив процессор, подошел ко входу в ту же критическую секцию
3. H не может войти (L уже в критической секции)
4. H начинает busy waiting в цикле
5. L не получает управления (H имеет более высокий приоритет и постоянно занимает процессор)
6. L не может выйти из критической секции
7. **Результат:** Тупиковая ситуация (deadlock)

**Парадокс:**
- Высокоприоритетный процесс H ждет низкоприоритетный процесс L
- Но L никогда не получит процессор, чтобы завершить свою работу
- Фактически высокоприоритетный процесс заблокирован навсегда

#### Решения проблемы инверсии приоритетов
1. **Наследование приоритетов (Priority Inheritance):**
   - Когда H блокируется на ресурсе, удерживаемом L
   - L временно получает приоритет H
   - После освобождения ресурса приоритет L возвращается к исходному

2. **Потолок приоритета (Priority Ceiling):**
   - Каждому ресурсу назначается максимальный приоритет процессов, которые могут его использовать
   - Процесс, захвативший ресурс, получает этот приоритет

3. **Использование блокирующих примитивов синхронизации:**
   - Вместо busy waiting использовать блокировку с передачей управления
   - Процесс переходит в состояние ожидания и не занимает процессор