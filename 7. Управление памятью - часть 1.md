#Operating_Systems #OS_Memory
## Введение в управление памятью
### Иерархия памяти
Современные компьютерные системы используют иерархическую организацию памяти, основанную на различных уровнях, каждый из которых имеет свои характеристики производительности, стоимости и энергозависимости.

**Иерархия памяти (от быстрой к медленной):**
1. **Регистры процессора**
   - **Характеристики:** самая быстрая, самая дорогая, энергозависимая
   - **Расположение:** внутри процессора
   - **Объём:** несколько десятков байт
   - **Время доступа:** доля наносекунды (один такт процессора)
   - **Назначение:** хранение операндов текущих операций

2. **Кэш-память (Cache)**
   - **Характеристики:** очень быстрая, дорогая, энергозависимая
   - **Уровни:** L1 (самый быстрый, ~32-64 КБ), L2 (~256 КБ - 1 МБ), L3 (несколько МБ)
   - **Время доступа:** несколько наносекунд
   - **Назначение:** буферизация часто используемых данных из оперативной памяти

3. **Оперативная память (RAM - Random Access Memory)**
   - **Характеристики:** среднескоростная, менее дорогая, энергозависимая
   - **Объём:** гигабайты
   - **Время доступа:** десятки-сотни наносекунд
   - **Назначение:** хранение выполняемых программ и данных

4. **Электронный диск / ПЗУ (ROM)**
   - **Характеристики:** среднескоростная, дорогая, энергонезависимая
   - **Назначение:** хранение неизменяемых данных, BIOS

5. **Твердотельный накопитель (SSD)**
   - **Характеристики:** быстрая, относительно дорогая, энергонезависимая
   - **Время доступа:** доли миллисекунды
   - **Назначение:** постоянное хранение данных и программ

6. **Магнитный диск (HDD)**
   - **Характеристики:** медленная, недорогая, энергонезависимая
   - **Время доступа:** миллисекунды
   - **Назначение:** массовое хранение данных

7. **Оптические диски, магнитные ленты**
   - **Характеристики:** очень медленная, очень дешёвая, энергонезависимая
   - **Назначение:** архивное хранение данных

**Принцип работы иерархии:**
- Данные перемещаются между уровнями автоматически
- Чем выше уровень, тем быстрее доступ, но меньше объём
- Операционная система управляет перемещением данных между уровнями

---
## Оперативная память и принципы её работы
### Основные характеристики оперативной памяти
**Оперативная память** — это основная память компьютера, используемая для хранения данных и программ, непосредственно участвующих в вычислительном процессе.

**Ключевые особенности:**
1. **Архитектура фон Неймана:**
   - Процессор может выполнять инструкции **только** в том случае, если они находятся в оперативной памяти
   - Процессор может прямо обращаться только к регистрам и оперативной памяти
   - Для работы с данными на диске они должны быть сначала загружены в оперативную память
1. **Структура памяти:**
   - **Память — массив слов** (ячейки-биты объединяются в байты, байты — в слова)
   - **Единица адресации и обмена** — слово (обычно 4 или 8 байт в современных системах)
   - Каждая ячейка памяти имеет уникальный адрес
1. **Принцип работы процессора с памятью:**
   - Процессор выбирает команду по адресу, хранящемуся в **счётчике команд** (Program Counter)
   - Для выполнения команды может понадобиться обратиться за данными в память
   - После выполнения команды счётчик команд увеличивается, указывая на следующую инструкцию

### Обращение к памяти и производительность
**Проблема задержек при обращении к памяти:**
- **Операции в регистрах:** процессор может декодировать команду и выполнить операцию над операндами, хранящимися в регистрах, за **один такт** часов (или даже несколько операций в современных процессорах с суперскалярной архитектурой)

- **Обращение к оперативной памяти:** происходит через **шину памяти** и занимает **несколько тактов** (десятки-сотни тактов)
	- **Простой процессора:** В время ожидания данных из памяти процессор будет простаивать, так как ему «нечего делать», что недопустимо, учитывая что обращения к памяти происходят постоянно

**Решения проблемы:**
1. **Кэш-память** — буферизация часто используемых данных
2. **Предсказание ветвлений** — загрузка данных заранее
3. **Конвейеризация** — выполнение нескольких инструкций одновременно
4. **Многопоточность** — переключение на другой поток во время ожидания

### Распределение оперативной памяти
Память распределяется между:
- **Модулями прикладных программ** (пользовательские процессы)
- **Модулями операционной системы** (ядро, драйверы, системные службы)
---
## История и эволюция управления памятью
### Ранние операционные системы
**Простое управление памятью:**
- В ранних ОС управление памятью сводилось просто к **загрузке программы и её данных** из внешнего накопителя (перфоленты, магнитной ленты или магнитного диска) в память
- **Однопрограммный режим:** в памяти находилась только одна программа
- **Абсолютная адресация:** программа загружалась всегда по фиксированному адресу

### Эра мультипрограммирования
С появлением **мультипрограммирования** перед ОС были поставлены новые задачи:
- Распределение имеющейся памяти между **несколькими одновременно выполняющимися программами**
- Защита памяти одной программы от другой
- Эффективное использование ограниченных ресурсов памяти
- Поддержка виртуальной памяти
---
## Функции операционной системы по управлению памятью
Современная операционная система выполняет следующие ключевые функции управления памятью:
### 1. Отслеживание свободной и занятой памяти
**Задача:** ОС должна знать, какие области памяти свободны, а какие заняты
**Методы отслеживания:**
- **Битовые карты** — каждый бит соответствует блоку памяти (0 — свободен, 1 — занят)
- **Связные списки** — список свободных и занятых областей памяти
- **Деревья** — для быстрого поиска свободных блоков нужного размера
- **Таблицы дескрипторов** — структуры данных, описывающие распределение памяти

### 2. Выделение памяти процессам
**При создании процесса:**
- ОС выделяет память для кода программы
- Выделяется память для данных процесса
- Создаётся стек для локальных переменных
- Резервируется место для кучи (heap) для динамического выделения

**Освобождение памяти:**
- По завершении процесса вся занятая им память освобождается
- Память возвращается в пул свободной памяти

### 3. Вытеснение процессов на диск (свопинг)
**Свопинг (Swapping):**
- Когда размеры основной памяти недостаточны для размещения всех процессов
- Коды и данные процессов **вытесняются** из оперативной памяти на диск (полностью или частично)
- При необходимости они **возвращаются** в оперативную память

**Виды свопинга:**
- **Полное вытеснение** — весь процесс записывается на диск
- **Частичное вытеснение** — вытесняются только неиспользуемые страницы (страничная организация)

### 4. Настройка адресов программы
**Преобразование адресов:**
- **Логические (виртуальные) адреса** → **Физические адреса**
- Привязка программы к конкретной области физической памяти
- Обеспечение изоляции адресных пространств разных процессов
---
## Дефрагментация памяти
### Проблема фрагментации
**Динамическое распределение памяти:**
- Помимо первоначального выделения памяти процессам при их создании, ОС должна заниматься **динамическим распределением памяти**
- Приложения выполняют запросы на выделение дополнительной памяти во время выполнения
- После использования приложение может возвратить память системе

**Причина фрагментации:**
- Выделение памяти **случайной длины** в **случайные моменты времени** из общего пула памяти
- Это приводит к фрагментации и неэффективному использованию памяти

### Виды фрагментации
**1. Внешняя фрагментация:**
- Между занятыми блоками памяти остаются небольшие свободные промежутки
- Общий объём свободной памяти достаточен, но она разбросана по маленьким кускам
- Невозможно выделить большой непрерывный блок памяти

**2. Внутренняя фрагментация:**
- Выделенный блок памяти больше, чем запрошено
- Остаток блока не используется, но и не доступен для других процессов
- Характерна для систем с фиксированным размером блоков

### Методы борьбы с фрагментацией
**Дефрагментация памяти:**
- Перемещение занятых блоков памяти так, чтобы они располагались последовательно
- Объединение маленьких свободных блоков в большие непрерывные области
- **Стоимость:** требует остановки или замедления работы процессов

**Альтернативные подходы:**
- **Страничная организация памяти** — память делится на страницы фиксированного размера
- **Сегментная организация** — логическое деление памяти на сегменты
- **Виртуальная память** — использование диска как расширения оперативной памяти

![[OS 40.png]]

---
## Память для нужд операционной системы
### Системные структуры данных

**Во время работы ОС создаёт множество служебных структур:**
- **Описатели процессов и потоков** (Process Control Block, Thread Control Block)
- **Таблицы распределения ресурсов** (память, файлы, устройства)
- **Буферы** для обмена данными между процессами
- **Синхронизирующие объекты** (семафоры, мутексы, события)
- **Таблицы страниц** для виртуальной памяти
- **Кэши файловой системы**

Все эти системные объекты **требуют памяти**.

### Подходы к выделению памяти для ОС
**1. Статическое резервирование:**
- Заранее (во время установки) резервируется **фиксированный объём памяти** для системных нужд
- **Преимущества:** простота, предсказуемость
- **Недостатки:** неэффективное использование памяти, негибкость

**2. Динамическое выделение:**
- Память для системных целей выделяется **динамически** по мере необходимости
- Разные подсистемы ОС при создании своих таблиц, объектов и структур обращаются к подсистеме управления памятью с запросами
- **Преимущества:** эффективное использование памяти, гибкость
- **Недостатки:** сложность управления, возможность нехватки памяти

**Современный подход:**
- Большинство современных ОС используют **гибридный подход**
- Часть памяти резервируется статически для критических компонентов
- Остальная память выделяется динамически
---
## Защита памяти
### Необходимость защиты памяти
**Защита памяти** — важнейшая задача операционной системы, которая состоит в том, чтобы не позволить выполняемому процессу **записывать или читать данные** из памяти, назначенной другому процессу.

**Цели защиты памяти:**
1. **Изоляция процессов** — предотвращение взаимного влияния процессов
2. **Безопасность** — защита от вредоносного кода
3. **Стабильность системы** — предотвращение случайных ошибок одного процесса от влияния на другие
4. **Защита ядра ОС** — предотвращение доступа пользовательских процессов к памяти ядра

### Механизмы защиты памяти
**1. Аппаратные механизмы:**
- **Регистры границ** — определяют допустимый диапазон адресов для процесса
- **Биты защиты** в таблицах страниц (чтение, запись, выполнение)
- **Кольца защиты** (rings) — уровни привилегий (0 — ядро, 3 — пользователь)
- **MMU (Memory Management Unit)** — аппаратный блок управления памятью

**2. Программные механизмы:**
- **Виртуальные адресные пространства** — каждый процесс имеет своё изолированное пространство
- **Проверка прав доступа** при каждом обращении к памяти
- **Обработка исключений** — реакция на нарушения доступа

**Взаимодействие:**
- Функция защиты памяти реализуется **программными модулями ОС** в тесном взаимодействии с **аппаратными средствами**
- Аппаратура выполняет быструю проверку, ОС управляет политикой защиты

**Последствия нарушения:**
- **Segmentation Fault** — попытка доступа к чужой памяти
- **Access Violation** — нарушение прав доступа
- **Завершение процесса** — операционная система принудительно завершает нарушителя
---
## Типы адресов в системе
При работе с памятью в компьютерной системе используются три типа адресов, которые соответствуют разным этапам жизненного цикла программы.
### 1. Символьные имена (Symbolic Names)
**Определение:**
- Присваиваются **пользователем** при написании программы на алгоритмическом языке или ассемблере
- Представляют собой имена переменных, функций, меток

**Примеры:**
```c
int count;              // символьное имя переменной
void calculateSum();    // символьное имя функции
label_start:            // символьная метка
```

**Характеристики:**
- Удобны для программиста
- Не зависят от расположения в памяти
- Используются на этапе разработки

### 2. Виртуальные (логические) адреса
**Определение:**
- Вырабатываются **транслятором** (компилятором/ассемблером), переводящим программу на машинный язык
- Представляют собой числовые адреса в виртуальном адресном пространстве

**Особенности генерации:**
- Во время трансляции в общем случае **не известно**, в какое место оперативной памяти будет загружена программа
- Транслятор присваивает переменным и командам **виртуальные (условные) адреса**
- Обычно считается по умолчанию, что **начальным адресом программы будет нулевой адрес**

**Диапазон адресов:**
- Для 32-битных систем: `0x00000000` — `0xFFFFFFFF` (4 ГБ)
- Для 64-битных систем: `0x0000000000000000` — `0xFFFFFFFFFFFFFFFF` (теоретически 16 эксабайт)

**Примеры:**
```
Виртуальный адрес переменной: 0x00001A4C
Виртуальный адрес функции:    0x00002B80
```

### 3. Физические адреса
**Определение:**
- Соответствуют **номерам ячеек оперативной памяти**, где в действительности расположены или будут расположены переменные и команды
- Реальные адреса в аппаратной памяти компьютера

**Характеристики:**
- Определяются операционной системой во время загрузки программы
- Могут изменяться во время выполнения (при перемещении программы в памяти)
- Уникальны в пределах физической памяти системы

**Примеры:**
```
Физический адрес: 0x7FF4A000
Физический адрес: 0x80120000
```

### Преобразование адресов

![[OS 41.png]]

**Цепочка преобразований:**
```
Исходный код (символьные имена)
    ↓ [Компилятор/Ассемблер]
Объектный код (виртуальные адреса)
    ↓ [Компоновщик]
Исполняемый файл (виртуальные адреса)
    ↓ [Загрузчик/ОС]
Процесс в памяти (физические адреса)
```

---
## Жизненный цикл программы и преобразование адресов
### Этапы создания и выполнения программы
**Полный жизненный цикл программы включает несколько этапов, на каждом из которых происходит преобразование или использование адресов:**
#### 1. Компиляция (Compilation)
**Вход:** Исходная программа с символьными адресами

**Процесс:**
- **Компилятор или ассемблер** переводит исходный код на машинный язык
- Символьные имена заменяются на **логические (виртуальные) адреса**
- Создаются один или несколько **объектных модулей**

**Выход:** Объектные модули (`.o`, `.obj` файлы)

**Используемые адреса:** Логические (виртуальные)

#### 2. Компоновка/Связывание (Linking)
**Вход:** 
- Один или несколько объектных модулей
- Системные библиотеки (статические)

**Процесс:**
- **Редактор связей (линкер)** объединяет объектные модули
- Разрешает внешние ссылки между модулями
- Подключает функции из библиотек
- Создаёт единый **загрузочный модуль**

**Выход:** Загрузочный модуль (исполняемый файл `.exe`, `.elf`)

**Используемые адреса:** Логические (виртуальные)

#### 3. Загрузка (Loading)
**Вход:** Загрузочный модуль

**Процесс:**
- **Загрузчик ОС** читает исполняемый файл
- Выделяет память для процесса
- Создаёт виртуальное адресное пространство
- Может подключить **динамические библиотеки**
- Выполняет **преобразование логических адресов в физические**

**Выход:** Двоичный образ процесса в памяти
**Используемые адреса:** Физические (реальные адреса в RAM)

#### 4. Динамическое связывание (Dynamic Linking)
**Процесс:**
- Происходит **во время выполнения программы**
- Динамические библиотеки (`.dll`, `.so`) загружаются по требованию
- Адреса функций разрешаются при первом вызове

**Преимущества:**
- Экономия памяти (библиотека загружается один раз для всех процессов)
- Возможность обновления библиотек независимо от программ
- Уменьшение размера исполняемого файла

#### 5. Исполнение (Execution)
**Процесс:**
- Программа выполняется в виртуальном адресном пространстве
- **MMU (Memory Management Unit)** преобразует виртуальные адреса в физические при каждом обращении к памяти
- ОС управляет памятью процесса

**Используемые адреса:** 
- В командах процессора — виртуальные
- При доступе к RAM — физические (после преобразования MMU)

### Типы адресов на разных этапах

| Этап               | Файл                 | Тип адресов              |
| ------------------ | -------------------- | ------------------------ |
| Исходный код       | `.c`, `.cpp`, `.asm` | Символические имена      |
| Объектный модуль   | `.o`, `.obj`         | Логические (виртуальные) |
| Загрузочный модуль | `.exe`, `.elf`       | Логические (виртуальные) |
| Процесс в памяти   | —                    | Физические адреса        |

---
## Виртуальное адресное пространство
### Определение и основные понятия
**Виртуальное адресное пространство** — это совокупность виртуальных адресов, доступных процессу.

**Виртуальный адрес** — это адрес, используемый программой для обращения к памяти, который не соответствует напрямую физическому адресу в оперативной памяти.

**Ключевые характеристики:**
1. **Единый диапазон для всех процессов:**
   - Диапазон возможных адресов виртуального пространства у всех процессов является **одним и тем же**
   - Для 32-битных систем: `0x00000000` — `0xFFFFFFFF` (4 ГБ)
   - Для 64-битных систем: `0x0000000000000000` — `0xFFFFFFFFFFFFFFFF`

2. **Изоляция процессов:**
   - **Каждый процесс имеет собственное виртуальное адресное пространство**
   - Транслятор присваивает виртуальные адреса переменным и кодам каждой программы **независимо**
   - Процессы не могут напрямую обращаться к памяти друг друга

3. **Отображение на физическую память:**
   - Виртуальные адреса преобразуются в физические операционной системой
   - Разные процессы с одинаковыми виртуальными адресами отображаются на разные физические адреса

![[OS 42.png]]

**Пример:**
```
Процесс A: виртуальный адрес 0x00001000 → физический адрес 0x12345000
Процесс B: виртуальный адрес 0x00001000 → физический адрес 0x67890000
Процесс C: виртуальный адрес 0x00001000 → физический адрес 0xABCDE000
```

### Структура виртуального адресного пространства
Существуют различные способы организации виртуального адресного пространства.
#### 1. Линейная (плоская) структура
**Линейное виртуальное адресное пространство:**
- Представлено в виде **непрерывной линейной последовательности** виртуальных адресов
- Структура называется **плоской (flat)**
- **Линейный виртуальный адрес** — единственное число, представляющее собой смещение относительно начала (обычно `0x00000000`) виртуального адресного пространства

**Характеристики:**
- Простая организация
- Один адрес однозначно определяет положение в памяти
- Используется в большинстве современных ОС (Linux, Windows)

**Формат адреса:**
```
Адрес = смещение (offset)
Например: 0x00401234
```

#### 2. Сегментная структура
**Сегментированное адресное пространство:**
- Виртуальное адресное пространство делится на части, называемые **сегментами** (или секциями, или областями)
- **Виртуальный адрес** представляет собой **пару чисел (n, m)**:
  - `n` — номер сегмента (selector)
  - `m` — смещение внутри сегмента (offset)

**Преимущества:**
- Логическое разделение программы (код, данные, стек)
- Упрощение совместного использования кода
- Защита на уровне сегментов

**Формат адреса:**
```
Адрес = (сегмент : смещение)
Например: (0x0010 : 0x00001234)
```

**Типичные сегменты:**
- **Сегмент кода** — исполняемые инструкции
- **Сегмент данных** — глобальные и статические переменные
- **Сегмент стека** — локальные переменные и вызовы функций

#### 3. Более сложные структуры
Существуют более сложные способы структуризации, когда виртуальный адрес образуется **тремя или даже более числами**:
```
Адрес = (сегмент : таблица : страница : смещение)
```
---
## Отображение виртуального адресного пространства на физическую память
### Задача операционной системы
**Задача:** Отображение индивидуальных виртуальных адресных пространств **всех одновременно выполняющихся процессов** на **общую физическую память**.

**Особенности:**
- ОС отображает либо **всё** виртуальное адресное пространство, либо только **определённую его часть**
- Процедура преобразования виртуальных адресов в физические должна быть **максимально прозрачна** для пользователя и программиста
- Преобразование должно происходить **быстро** (аппаратная поддержка)

### Два подхода к преобразованию адресов
Существуют два принципиально отличающихся подхода к преобразованию виртуальных адресов в физические.

---
## Статическое преобразование адресов
### Принцип работы
**Статическое преобразование** — замена виртуальных адресов на физические выполняется **один раз** для каждого процесса во время **начальной загрузки программы** в память.

**Механизм:**
1. **Перемещающий загрузчик** — специальная системная программа
2. **Исходные данные:**
   - Начальный адрес физической памяти, куда предстоит загружать программу
   - Информация от транслятора об **адресно-зависимых элементах** программы (релокационная информация)
3. **Процесс загрузки:**
   - Загрузчик читает программу из файла
   - При загрузке одновременно выполняет замену виртуальных адресов физическими
   - К каждому виртуальному адресу добавляется базовый адрес загрузки

**Формула преобразования:**
```
Физический_адрес = Виртуальный_адрес + Базовый_адрес_загрузки
```

**Пример:**
```
Базовый адрес загрузки: 0x10000000
Виртуальный адрес команды: 0x00001234
Физический адрес после загрузки: 0x10001234
```

### Характеристики статического преобразования
**Преимущества:**
- **Простота** реализации
- **Экономичность:** каждый виртуальный адрес преобразуется только **один раз** во время загрузки
- Нет накладных расходов во время выполнения программы
- Не требуется аппаратная поддержка преобразования адресов

**Недостатки:**
- **Жёсткая привязка** программы к первоначально выделенному участку памяти
- **Невозможность перемещения** программы в другую область памяти во время выполнения
- Затрудняет реализацию виртуальной памяти
- Проблемы с разделением кода между процессами

**Применение:**
- Ранние операционные системы
- Специализированные встраиваемые системы
- Системы реального времени с предсказуемым размещением
---
## Динамическое преобразование адресов
### Принцип работы
**Динамическое преобразование** — программа загружается в память **в неизменённом виде** в виртуальных адресах, то есть операнды инструкций и адреса переходов имеют те значения, которые выработал транслятор.

**Механизм:**
1. **Загрузка без модификации:**
   - Программа загружается с виртуальными адресами
   - Код программы не изменяется

2. **Преобразование во время выполнения:**
   - **При каждом обращении к оперативной памяти** выполняется преобразование виртуального адреса в физический
   - Операционная система фиксирует **смещение** действительного расположения программного кода относительно виртуального адресного пространства

3. **Аппаратная поддержка:**
   - ОС помещает значение начального смещения `S` в **специальный регистр процессора** (базовый регистр)
   - При обращении к памяти виртуальные адреса преобразуются в физические **путём прибавления смещения** `S`

### Простой случай — единые непрерывные области
**Условия:**
- Виртуальная память процесса — единая непрерывная область адресов
- Физическая память процесса — единая непрерывная область адресов

**Формула преобразования:**
```
Физический_адрес = Виртуальный_адрес + S

где S — содержимое базового регистра (начальное смещение)
```

**Пример:**
```
Базовый регистр S: 0x20000000
Виртуальный адрес в команде: 0x00001ABC
Физический адрес при выполнении: 0x20001ABC
```

### Аппаратная поддержка динамического преобразования
**MMU (Memory Management Unit):**
- Аппаратный блок управления памятью
- Выполняет преобразование адресов **автоматически** при каждом обращении к памяти
- Работает параллельно с процессором (минимальные задержки)

**Базовый регистр (Base Register):**
- Хранит начальный физический адрес процесса
- Загружается операционной системой при переключении контекста
- Доступен только в привилегированном режиме (защита)

**Граничный регистр (Limit Register):**
- Хранит размер виртуального адресного пространства процесса
- Используется для проверки допустимости адресов
- Предотвращает выход за пределы выделенной памяти

**Проверка при обращении к памяти:**
```
if (Виртуальный_адрес >= Граничный_регистр) {
    // Ошибка: выход за пределы адресного пространства
    генерировать_исключение(SEGMENTATION_FAULT);
} else {
    Физический_адрес = Виртуальный_адрес + Базовый_регистр;
}
```


### Характеристики динамического преобразования
**Преимущества:**
- **Возможность перемещения** программного кода процесса в течение всего периода его выполнения
- Программа не привязана к конкретной области физической памяти
- Упрощается реализация виртуальной памяти
- Возможность разделения физической памяти между процессами
- Поддержка свопинга (вытеснения процессов на диск)

**Недостатки:**
- **Накладные расходы:** преобразование каждого виртуального адреса происходит при **каждом обращении** по данному адресу
- Требуется аппаратная поддержка (MMU)
- Небольшое замедление выполнения программы

**Оптимизация:**
- Использование кэша преобразования адресов — **TLB (Translation Lookaside Buffer)**
- TLB хранит недавние преобразования виртуальных адресов в физические
- Попадание в TLB даёт преобразование за один такт

---
## Сравнение способов преобразования адресов
### Таблица сравнения

| Характеристика | Статическое преобразование | Динамическое преобразование |
|----------------|----------------------------|----------------------------|
| **Момент преобразования** | Один раз при загрузке | При каждом обращении к памяти |
| **Модификация кода** | Да, адреса изменяются | Нет, код остаётся неизменным |
| **Перемещение в памяти** | Невозможно | Возможно в любой момент |
| **Накладные расходы** | Только при загрузке | При каждом обращении к памяти |
| **Аппаратная поддержка** | Не требуется | Требуется (MMU) |
| **Виртуальная память** | Сложно реализовать | Легко реализуется |
| **Разделение кода** | Затруднено | Упрощено |
| **Применение** | Специализированные системы | Современные ОС общего назначения |

### Специальный случай — физические адреса от транслятора
В некоторых случаях (обычно в **специализированных системах**), когда заранее точно известно, в какой области оперативной памяти будет выполняться программа, транслятор может выдавать исполняемый код **сразу в физических адресах**.

**Применение:**
- Встраиваемые системы (embedded systems)
- Контроллеры с фиксированной конфигурацией памяти
- Прошивки (firmware)
- Системы реального времени с жёсткими требованиями к производительности

**Преимущества:**
- Нет преобразования адресов вообще
- Максимальная производительность

**Недостатки:**
- Полное отсутствие гибкости
- Невозможность изменения размещения программы
- Сложность разработки и отладки
---
## Динамическая загрузка программ
### Проблема статичной загрузки

**При статичной загрузке:**
- **Вся программа и все данные** загружаются в память целиком
- Образ программы **не может быть больше** размера физической памяти
- Неиспользуемые части программы занимают память напрасно

**Примеры неэффективности:**
- Обработчики редких ошибок, которые могут никогда не выполниться
- Альтернативные ветви кода (разные алгоритмы для разных условий)
- Отладочная информация и диагностический код

### Принцип динамической загрузки
**Динамическая загрузка** — метод, при котором подпрограмма загружается **только при обращении к ней**.

**Механизм:**
1. **Хранение на диске:**
   - Все подпрограммы хранятся на диске в **перемещаемом формате**
   - Главная программа загружается и начинает выполняться

2. **Загрузка по требованию:**
   - При обращении к подпрограмме вызывающая программа **проверяет**, загружена ли вызываемая в память
   - Если подпрограмма **не загружена**:
     - Вызывается **перемещающий динамический загрузчик**
     - Загрузчик загружает нужную подпрограмму в память
     - **Таблица адресов программы обновляется**
     - Управление передается вызываемой подпрограмме
   - Если подпрограмма **уже загружена**:
     - Управление сразу передается подпрограмме

3. **Выгрузка:**
   - Неиспользуемые подпрограммы могут быть выгружены для освобождения памяти
   - Используются алгоритмы замещения (LRU, FIFO)

### Преимущества динамической загрузки
**1. Экономия памяти:**
- В памяти находится только **небольшой фрагмент программы**, который постоянно используется
- Если подпрограмма не вызывается, она **никогда не будет загружена**

**2. Возможность выполнения больших программ:**
- Программа может быть больше размера физической памяти
- В память загружается только необходимая часть

**3. Особая полезность для редких событий:**
- Обработка редких исключений и ошибок
- Диагностический и отладочный код
- Альтернативные алгоритмы для специфических случаев

**Пример:**
```
Программа размером 100 МБ
В памяти одновременно: 5-10 МБ активного кода
Экономия памяти: 90-95 МБ
```

### Ответственность за реализацию
**Подход без поддержки ОС:**
- От операционной системы **не требуется** никаких особенных действий
- Всё определяет **структура программы**
- **Ответственность** за эффективное использование памяти перекладывается на **программиста**
- Программист должен разработать систему загрузки и выгрузки модулей

**Поддержка со стороны ОС:**
- ОС может помочь программисту за счёт использования **динамических библиотек**
- Операционная система берёт на себя управление загрузкой/выгрузкой
- Прозрачный механизм для программиста
---
## Статичное и динамическое связывание (линковка)
### Статичное связывание (Static Linking)
**Определение:**
Библиотеки **включаются в двоичный образ** процесса **при загрузке** (точнее, на этапе компоновки).

**Механизм:**
1. Линкер берёт объектные файлы программы
2. Извлекает необходимые функции из статических библиотек (`.a`, `.lib`)
3. Копирует код библиотечных функций в исполняемый файл
4. Создаёт единый самодостаточный исполняемый файл

**Преимущества:**
- **Самодостаточность:** программа содержит весь необходимый код
- **Предсказуемость:** нет зависимости от внешних библиотек
- **Производительность:** нет накладных расходов на загрузку библиотек
- **Простота распространения:** один файл содержит всё необходимое

**Недостатки:**
- **Большой размер** исполняемых файлов (дублирование кода библиотек)
- **Расход памяти:** каждая программа содержит свою копию библиотечного кода
- **Отсутствие обновлений:** для обновления библиотеки нужно перекомпилировать программу
- **Медленная загрузка:** весь код загружается сразу

### Динамическое связывание (Dynamic Linking)
**Определение:**
Библиотека **прилинковывается во время выполнения** программы.

**Механизм:**
1. **Компоновка:**
   - В исполняемый файл включаются только **ссылки** на функции из динамических библиотек
   - Каждая ссылка содержит небольшой участок кода — **stub** (заглушка)

2. **Stub (заглушка):**
   - Описывает, как **найти резидентную функцию** в памяти
   - Описывает, как **загружать библиотеку**, если она ещё не загружена

3. **Выполнение stub:**
   - При первом вызове функции выполняется stub
   - Stub выясняет, загружена ли библиотека
   - Если библиотека **не загружена**:
     - Stub загружает библиотеку в память
     - Разрешает адреса всех функций библиотеки
   - Если библиотека **уже загружена**:
     - Stub просто находит адрес нужной функции
   - Stub заменяет себя **адресом реальной функции** в таблице вызовов
   - При последующих вызовах stub уже не выполняется, происходит прямой вызов функции

4. **Разделяемая память:**
   - Одна копия библиотеки в памяти используется **всеми процессами**
   - Экономия физической памяти

**Типы динамических библиотек:**
- **Windows:** `.dll` (Dynamic Link Library)
- **Linux:** `.so` (Shared Object)
- **macOS:** `.dylib` (Dynamic Library)

### Преимущества динамического связывания
**1. Экономия памяти:**
- Библиотека загружается в память **один раз**
- Все процессы **разделяют** одну копию кода библиотеки
- Значительная экономия при использовании популярных библиотек (libc, GUI и т.д.)

**2. Экономия дискового пространства:**
- Исполняемые файлы **меньше**
- Код библиотек хранится отдельно

**3. Обновление библиотек:**
- Возможность **обновления библиотек** независимо от программ
- Исправление ошибок в библиотеке без перекомпиляции приложений
- Обновление безопасности

**4. Модульность:**
- Возможность создания плагинов
- Динамическое расширение функциональности

### Недостатки динамического связывания
**1. Проблемы совместимости:**
- **"DLL Hell"** (в Windows) — конфликты версий библиотек
- Программа может не запуститься, если библиотека отсутствует или неправильной версии

**2. Накладные расходы:**
- Время на загрузку библиотек при первом обращении
- Накладные расходы на разрешение адресов (stub)

**3. Сложность распространения:**
- Нужно распространять программу вместе с библиотеками
- Или полагаться на наличие библиотек в системе

### Таблица сравнения связывания

| Характеристика | Статическое связывание | Динамическое связывание |
|----------------|------------------------|-------------------------|
| **Момент связывания** | При компоновке (до запуска) | Во время выполнения |
| **Размер исполняемого файла** | Большой | Маленький |
| **Использование памяти** | Дублирование кода | Разделяемый код |
| **Зависимость от библиотек** | Нет | Да |
| **Обновление библиотек** | Требует перекомпиляции | Независимое |
| **Производительность** | Выше | Небольшие накладные расходы |
| **Надёжность запуска** | Выше | Зависит от наличия библиотек |
| **Применение** | Встраиваемые системы | Современные ОС общего назначения |

---
## Максимальный размер виртуального адресного пространства
### Ограничения виртуального адресного пространства

**Основное ограничение:**
Максимальный размер виртуального адресного пространства ограничивается только **разрядностью адреса**, присущей данной архитектуре компьютера.

**Размеры виртуального адресного пространства:**
- **32-битная архитектура:**
  - Адрес: 32 бита
  - Диапазон: `0x00000000` — `0xFFFFFFFF`
  - Максимальный размер: **4 ГБ** (2³² байт)
  
- **64-битная архитектура:**
  - Адрес: 64 бита
  - Диапазон: `0x0000000000000000` — `0xFFFFFFFFFFFFFFFF`
  - Теоретический максимальный размер: **16 эксабайт** (2⁶⁴ байт)
  - Практическое использование: современные процессоры используют только 48 бит (256 ТБ)

### Несоответствие виртуальной и физической памяти
**Типичная ситуация:**
Максимальный размер виртуального адресного пространства, как правило, **не совпадает** с объёмом физической памяти, имеющимся в компьютере.

**Современные системы общего назначения:**
- Объём виртуального адресного пространства **превышает** доступный объём оперативной памяти
- Это ключевая особенность современных ОС

**Примеры:**
```
32-битная система:
- Виртуальное адресное пространство: 4 ГБ
- Физическая память (RAM): 2 ГБ
- Превышение: в 2 раза

64-битная система:
- Виртуальное адресное пространство: 256 ТБ (практически)
- Физическая память (RAM): 16 ГБ
- Превышение: в 16 000 раз
```

### Решение проблемы несоответствия — виртуальная память
**Механизм:**
В случае, когда объём виртуального адресного пространства превышает размер физической памяти, операционная система для хранения данных виртуального адресного пространства процесса, не помещающихся в оперативную память, использует **внешние накопители** (диск).

**Ключевые компоненты:**
1. **Swap-файл / Swap-раздел** (в Linux)
2. **Pagefile.sys** (в Windows)
3. **Файл подкачки** — общее название

**Принцип работы:**
- Активно используемые данные находятся в оперативной памяти
- Неиспользуемые данные **вытесняются** на диск (swapping, paging)
- При обращении к вытесненным данным они **возвращаются** в оперативную память
- Процесс автоматический и прозрачный для приложения

**Преимущества:**
- Процессы могут использовать больше памяти, чем физически доступно
- Возможность одновременного выполнения большего числа процессов
- Процесс не ограничен размером физической памяти

**Недостатки:**
- Обращение к диску **значительно медленнее**, чем к оперативной памяти (в тысячи раз)
- При интенсивной подкачке возникает **thrashing** (пробуксовка) — система тратит больше времени на подкачку, чем на выполнение программ
- Износ SSD при частой записи

---
## Виртуальный образ процесса
### Определение виртуального образа
**Виртуальный образ процесса (процессный образ)** — это содержимое назначенного процессу виртуального адресного пространства.

**Состав виртуального образа:**
1. **Коды команд** — машинные инструкции программы
2. **Исходные данные** — начальные значения переменных, константы
3. **Промежуточные данные** — данные, генерируемые во время выполнения
4. **Результаты вычислений** — выходные данные программы

### Структура виртуального образа процесса
Типичный виртуальный образ процесса состоит из нескольких **логических разделов (сегментов)**:

**1. Сегмент кода (Code/Text Segment):**
- Машинные инструкции программы
- **Только для чтения** (read-only)
- **Исполняемый** (executable)
- Может разделяться между процессами (общая библиотека)

**2. Сегмент данных (Data Segment):**
- **Инициализированные данные** — глобальные и статические переменные с начальными значениями
- **Неинициализированные данные (BSS — Block Started by Symbol)** — глобальные и статические переменные без начальных значений
- **Для чтения и записи** (read-write)

**3. Куча (Heap):**
- Область для **динамического выделения памяти**
- Растёт «вверх» (к большим адресам)
- Управляется функциями: `malloc()`, `new`, `calloc()`, `free()`, `delete`

**4. Стек (Stack):**
- **Локальные переменные** функций
- **Параметры функций**
- **Адреса возврата** из функций
- **Сохранённое состояние регистров**
- Растёт «вниз» (к меньшим адресам)
- Автоматическое управление (LIFO — Last In, First Out)

**5. Системные области:**
- Системные структуры данных
- Таблицы страниц
- Информация для отладки

![[OS 10.png]]

**Типичная организация виртуального адресного пространства (Linux x86-64):**
```
Высокие адреса (0xFFFFFFFFFFFFFFFF)
┌─────────────────────────────────┐
│   Пространство ядра (kernel)    │ ← Недоступно пользовательским программам
│        (128 ТБ верхних)         │
├─────────────────────────────────┤ 0x00007FFFFFFFFFFF
│          Стек (Stack)           │ ← Растёт вниз ↓
│               ↓                 │
│         (свободная зона)        │
│               ↑                 │
│          Куча (Heap)            │ ← Растёт вверх ↑
├─────────────────────────────────┤
│   Данные (Data, BSS)            │
├─────────────────────────────────┤
│      Код программы (Text)       │
└─────────────────────────────────┘ 0x0000000000000000
Низкие адреса
```

### Переходы между прикладными и системными кодами
**Постоянное взаимодействие:**
Во время работы процесса постоянно выполняются переходы от прикладных кодов к кодам операционной системы и обратно.

**Причины переходов к кодам ОС:**
1. **Явные вызовы системных функций** (system calls):
   - Открытие файла (`open()`, `CreateFile()`)
   - Чтение/запись данных (`read()`, `write()`)
   - Создание процесса/потока (`fork()`, `CreateThread()`)
   - Выделение памяти (`mmap()`, `VirtualAlloc()`)

2. **Реакция на внешние события (прерывания)**:
   - Таймер (переключение контекста)
   - Завершение операции ввода-вывода
   - Сетевые пакеты

3. **Исключительные ситуации (exceptions)**:
   - Деление на ноль
   - Нарушение доступа к памяти (segmentation fault)
   - Недопустимая инструкция
   - Page fault (обращение к странице, отсутствующей в памяти)

**Режимы выполнения:**
- **Пользовательский режим (User Mode)** — выполнение прикладного кода
  - Ограниченный доступ к ресурсам
  - Не может выполнять привилегированные инструкции
  
- **Привилегированный режим (Kernel Mode)** — выполнение кода ОС
  - Полный доступ к аппаратуре
  - Может выполнять любые инструкции

**Переключение между режимами:**
```
Прикладной код (User Mode)
    ↓ [Системный вызов / Прерывание / Исключение]
Код ОС (Kernel Mode)
    ↓ [Обработка завершена]
Прикладной код (User Mode)
```

### Необходимость присутствия кодов ОС в адресном пространстве

**Проблема:**
Для эффективного переключения между пользовательским и системным кодом необходимо, чтобы системные коды были **доступны** во время выполнения процесса.

**Решения:**
**Вариант 1: Системные коды в адресном пространстве процесса**
- Коды ОС отображаются в **каждое** виртуальное адресное пространство процесса
- Обычно в **верхней части** адресного пространства (высокие адреса)
- **Защищены** от прямого доступа пользовательского кода (доступны только в режиме ядра)
- **Преимущества:**
  - Быстрое переключение (не нужно менять контекст адресного пространства)
  - Нет накладных расходов на смену таблиц страниц
- **Недостатки:**
  - Уменьшается доступное пользовательское адресное пространство
  - Потенциальная угроза безопасности (уязвимости типа Meltdown/Spectre)

**Пример (Windows x86-64):**
```
0xFFFFFFFF80000000 - 0xFFFFFFFFFFFFFFFF: Пространство ядра (128 ТБ)
0x0000000000000000 - 0x00007FFFFFFFFFFF: Пространство пользователя (128 ТБ)
```

**Вариант 2: Отдельное адресное пространство ядра**
- Коды ОС находятся в **отдельном** адресном пространстве
- При системном вызове происходит **полное переключение** адресного пространства
- **Преимущества:**
  - Полная изоляция ядра (лучшая безопасность)
  - Больше места для пользовательских программ
- **Недостатки:**
  - Значительные накладные расходы на переключение адресных пространств
  - Необходимость сброса TLB (Translation Lookaside Buffer)

**Вариант 3: Гибридный подход (KPTI — Kernel Page Table Isolation)**
- Введён после обнаружения уязвимостей Meltdown и Spectre
- Используются **две таблицы страниц** для каждого процесса:
  - Пользовательская таблица страниц (минимальное отображение ядра)
  - Ядерная таблица страниц (полное отображение ядра)
- Переключение при системных вызовах и прерываниях

---
## Алгоритмы распределения памяти
### Основные вопросы управления памятью
При разработке системы управления памятью операционная система должна ответить на следующие **ключевые вопросы**:
1. **Непрерывность выделения:**
   - Следует ли назначать каждому процессу **одну непрерывную область** физической памяти?
   - Или можно выделять память **«кусками»** (фрагментами)?

2. **Перемещаемость:**
   - Должны ли сегменты программы, загруженные в память, **находиться на одном месте** в течение всего периода выполнения процесса?
   - Или можно их **время от времени перемещать** (сдвигать)?

3. **Переполнение памяти:**
   - Что делать, если сегменты программы **не помещаются** в имеющуюся физическую память?
   - Как обеспечить выполнение программ, превышающих размер оперативной памяти?

4. **Защита и изоляция:**
   - Как обеспечить **защиту** памяти одного процесса от другого?
   - Как предотвратить несанкционированный доступ?

**Разные операционные системы по-разному отвечают на эти базовые вопросы**, что приводит к различным алгоритмам распределения памяти.

### Классификация методов распределения памяти
Существует несколько фундаментальных подходов к организации памяти, которые можно классифицировать по различным критериям.

![[OS 43.png]]

**Основные классы методов распределения:**
**1. По способу выделения физической памяти:**
   - **Непрерывное распределение** — процессу выделяется один непрерывный блок физической памяти
   - **Распределение разделами** — память делится на разделы
   - **Страничное распределение** — память делится на страницы фиксированного размера
   - **Сегментное распределение** — память делится на сегменты переменного размера
   - **Сегментно-страничное** — комбинация сегментов и страниц

**2. По использованию виртуальной памяти:**
   - **Без виртуальной памяти** — программа выполняется только в оперативной памяти
   - **С виртуальной памятью** — часть данных может находиться на диске

**3. По размеру выделяемых областей:**
   - **Фиксированными разделами** — размер разделов определён заранее
   - **Динамическими разделами** — размер разделов определяется во время выполнения
   - **Перемещаемыми разделами** — разделы могут перемещаться для устранения фрагментации
---
## Распределение памяти фиксированными разделами
### Принцип работы
**Распределение памяти фиксированными разделами** — это простейший способ управления оперативной памятью.

**Основная идея:**
Память разбивается на несколько областей **фиксированной величины**, называемых **разделами (partitions)**.

**Установка разделов:**
- Разбиение может быть выполнено **вручную оператором** во время:
  - Старта системы (загрузки ОС)
  - Установки операционной системы
- После разбиения **границы разделов не изменяются** во время работы системы
- Размеры разделов могут быть **одинаковыми** или **различными**

**Размещение процессов:**
- В разделе может размещаться **только один процесс**
- Процесс загружается в раздел, размер которого **достаточен** для его размещения
- Если процесс меньше раздела, оставшееся место **не используется**

![[OS 44.png]]

**Пример конфигурации:**
```
Оперативная память (16 МБ):
┌─────────────────┐ 0x0000000000 
│   ОС (2 МБ)     │ ← Операционная система
├─────────────────┤ 0x0000200000
│  Раздел 1 (2МБ) │ ← Процесс A (1.8 МБ)
├─────────────────┤ 0x0000400000
│  Раздел 2 (4МБ) │ ← Свободен
├─────────────────┤ 0x0000800000
│  Раздел 3 (4МБ) │ ← Процесс B (3.5 МБ)
├─────────────────┤ 0x0000C00000
│  Раздел 4 (4МБ) │ ← Процесс C (2 МБ)
└─────────────────┘ 0x0001000000
```

### Задачи операционной системы при распределении фиксированными разделами
Подсистема управления памятью в этом случае выполняет следующие задачи:

**1. Ведение таблицы разделов:**
- ОС поддерживает таблицу, содержащую информацию о каждом разделе:
  - Начальный адрес раздела
  - Размер раздела
  - Состояние (свободен/занят)
  - Процесс, занимающий раздел (если занят)

**Пример таблицы разделов:**

| № раздела | Начальный адрес | Размер | Состояние | Процесс |
| --------- | --------------- | ------ | --------- | ------- |
| 1         | 0x00200000      | 2 МБ   | Занят     | PID 101 |
| 2         | 0x00400000      | 4 МБ   | Свободен  | —       |
| 3         | 0x00800000      | 4 МБ   | Занят     | PID 205 |
| 4         | 0x00C00000      | 4 МБ   | Занят     | PID 312 |

**2. Выбор подходящего раздела:**
- При поступлении нового процесса ОС:
  - **Сравнивает** объём памяти, требуемый для вновь поступившего процесса, с размерами **свободных разделов**
  - **Выбирает** подходящий раздел

**Стратегии выбора раздела:**
- **First-fit (первый подходящий)** — выбирается первый раздел достаточного размера
- **Best-fit (наилучший)** — выбирается наименьший раздел, в который помещается процесс
- **Worst-fit (наихудший)** — выбирается самый большой раздел для уменьшения фрагментации
- При разделах фиксированного размера часто используется **предопределённое соответствие** процессов разделам

**3. Загрузка программы и настройка адресов:**
- ОС осуществляет **загрузку программы** в выбранный раздел
- Выполняется **настройка адресов** (преобразование виртуальных адресов в физические)
- Уже на этапе **трансляции** разработчик может указать раздел, в который будет загружена программа

**4. Освобождение раздела:**
- После завершения процесса ОС:
  - Помечает раздел как **свободный**
  - Обновляет список (таблицу) свободных разделов
  - Раздел становится доступным для загрузки нового процесса

### Преимущества распределения фиксированными разделами
**1. Простота реализации:**
- Минимальные требования к системе управления памятью
- Простые структуры данных (таблица разделов)
- Несложная логика выделения и освобождения памяти

**2. Скорость выделения памяти:**
- Быстрый поиск свободного раздела (просмотр небольшой таблицы)
- Практически мгновенное выделение памяти процессу
- Нет накладных расходов на вычисления

**3. Предсказуемость:**
- Время выделения памяти детерминировано
- Подходит для систем реального времени
- Известно максимальное количество одновременно выполняемых процессов

**4. Отсутствие внешней фрагментации:**
- Нет маленьких «дыр» между занятыми областями
- Память чётко разделена на разделы

**5. Идеальность для специализированных систем:**
- Если количество или характер процессов **заранее известен** и **не меняется**
- Применяется в **встраиваемых системах** (embedded systems)
- Системы управления технологическими процессами
- Специализированные серверы с предсказуемой нагрузкой

### Недостатки распределения фиксированными разделами
**1. Ограничение размера процесса:**
- Процесс, размер которого **больше самого большого раздела**, никогда не сможет быть выполнен
- Нет возможности запустить процесс, превышающий размер максимального раздела
- **Пример:** Если максимальный раздел 4 МБ, процесс размером 5 МБ не может быть загружен

**2. Внутренняя фрагментация:**
- **Свободное пространство внутри раздела** не может быть использовано
- Если процесс меньше раздела, оставшаяся память **теряется**
- **Пример:** Процесс размером 2 МБ в разделе 4 МБ — потеря 2 МБ памяти

**Иллюстрация внутренней фрагментации:**
```
Раздел 4 МБ:
┌────────────────────┐
│   Процесс (2 МБ)   │ ← Используется
├────────────────────┤
│   ПОТЕРЯ (2 МБ)    │ ← Не используется, но и недоступна другим
└────────────────────┘
```

**3. Неэффективное использование памяти:**
- При средней внутренней фрагментации **до 50%** памяти может быть потрачено впустую
- Суммарно потери памяти могут быть значительными

**4. Негибкость:**
- Невозможно изменить размеры разделов без перезагрузки системы
- Сложно адаптироваться к изменяющейся нагрузке
- Неоптимальна для систем общего назначения с разнообразными процессами

**5. Ограниченная многозадачность:**
- Максимальное количество одновременно выполняемых процессов **ограничено** количеством разделов
- Даже если есть свободная память (в виде неиспользуемого пространства в занятых разделах)

**6. Проблема подбора размеров разделов:**
- Сложно выбрать оптимальные размеры разделов для разных типов процессов
- Слишком маленькие разделы — не вмещают процессы
- Слишком большие разделы — большая внутренняя фрагментация
---
## Распределение памяти динамическими разделами
### Принцип работы
**Распределение памяти динамическими разделами** — более гибкий метод управления памятью.

**Основная идея:**
- Память машины **не делится заранее** на разделы
- Сначала вся память, отводимая для приложений, **свободна**
- Разделы создаются **динамически** по запросу процессов

**Механизм выделения:**
1. **При создании процесса:**
   - Каждому вновь поступающему на выполнение приложению выделяется **вся необходимая ему память**
   - Если достаточный объём памяти **отсутствует**, то приложение **не принимается** на выполнение, и процесс для него не создаётся

2. **После завершения процесса:**
   - Память **освобождается**
   - На это место может быть загружен **другой процесс**

3. **В произвольный момент времени:**
   - Оперативная память представляет собой случайную последовательность **занятых и свободных участков (дыр — holes)** произвольного размера

![[OS 45.png]]

### Состояния памяти в разные моменты времени
**Иллюстрация динамического распределения:**

**Момент времени T1 (начальное состояние):**
```
┌──────────────┐
│  ОС (2 МБ)   │
├──────────────┤
│  Свободно    │
│   (14 МБ)    │
│              │
└──────────────┘
```

**Момент времени T2 (загружены процессы A, B, C):**
```
┌──────────────┐
│  ОС (2 МБ)   │
├──────────────┤
│ Процесс A    │ ← 3 МБ
│    (3 МБ)    │
├──────────────┤
│ Процесс B    │ ← 5 МБ
│    (5 МБ)    │
├──────────────┤
│ Процесс C    │ ← 2 МБ
│    (2 МБ)    │
├──────────────┤
│  Свободно    │ ← 4 МБ
│   (4 МБ)     │
└──────────────┘
```

**Момент времени T3 (процесс B завершился, запущен процесс D):**
```
┌──────────────┐
│  ОС (2 МБ)   │
├──────────────┤
│ Процесс A    │ ← 3 МБ
│    (3 МБ)    │
├──────────────┤
│ Процесс D    │ ← 1 МБ (загружен на место B)
│    (1 МБ)    │
├──────────────┤
│  Свободно    │ ← 4 МБ (остаток от B)
│   (4 МБ)     │
├──────────────┤
│ Процесс C    │ ← 2 МБ
│    (2 МБ)    │
├──────────────┤
│  Свободно    │ ← 4 МБ
│   (4 МБ)     │
└──────────────┘
```

**Момент времени T4 (процесс A завершился, запущен процесс E):**
```
┌──────────────┐
│  ОС (2 МБ)   │
├──────────────┤
│  Свободно    │ ← 3 МБ (после A)
│   (3 МБ)     │
├──────────────┤
│ Процесс D    │ ← 1 МБ
│    (1 МБ)    │
├──────────────┤
│  Свободно    │ ← 4 МБ
│   (4 МБ)     │
├──────────────┤
│ Процесс C    │ ← 2 МБ
│    (2 МБ)    │
├──────────────┤
│ Процесс E    │ ← 4 МБ
│    (4 МБ)    │
└──────────────┘
```

**Наблюдаемые эффекты:**
- Память **фрагментируется** на занятые и свободные области
- Свободные области имеют **различный размер**
- **Внешняя фрагментация** — свободная память разбросана по маленьким кускам

### Функции ОС при распределении динамическими разделами
**1. Ведение учёта свободных и занятых областей:**
- ОС ведёт **таблицы (списки)**, в которых указываются:
  - Начальные адреса участков памяти
  - Размеры участков
  - Состояние (свободен/занят)
  - Процесс-владелец (для занятых участков)

**2. Анализ требований к памяти:**
- При создании нового процесса ОС:
  - **Анализирует** требования к памяти нового процесса
  - **Просматривает** таблицу свободных областей (holes)
  - **Выбирает** раздел, размер которого достаточен для размещения кодов и данных нового процесса

**3. Выбор подходящего раздела:**
Выбор раздела может осуществляться по **разным правилам (алгоритмам)**:
- **First-fit (первый подходящий)**
- **Best-fit (наилучший)**
- **Worst-fit (наихудший)**
- **Next-fit (следующий подходящий)**


**4. Выделение памяти:**
- ОС выделяет выбранный участок памяти процессу
- Обновляет таблицы свободных и занятых областей
- Если участок больше требуемого, **оставшаяся часть** остаётся в списке свободных участков

**5. Освобождение памяти:**
- После завершения процесса ОС:
  - Помечает участок как **свободный**
  - **Объединяет (сливает)** соседние свободные участки в один больший участок
  - Обновляет таблицы свободных и занятых областей

### Алгоритмы выбора подходящего раздела
При создании нового процесса возникает необходимость просмотра списка всех **«дыр» (holes)**, чтобы найти свободное пространство, достаточное для размещения процесса.

#### 1. First-fit (первый подходящий)
**Принцип:**
- Просматривается список свободных областей от начала
- Выбирается **первый раздел**, в который может поместиться процесс
- **Не надо просматривать весь список** — останавливается на первом подходящем

**Начало поиска:**
- Можно начинать с **начала списка** (каждый раз)
- Можно начинать **там, где закончился предыдущий поиск** — это называется **Next-fit**

**Преимущества:**
- **Быстрый** — не требует просмотра всего списка
- **Простой** в реализации
- Обычно даёт хорошие результаты

**Недостатки:**
- Может оставлять маленькие неиспользуемые фрагменты в начале списка
- Постепенная фрагментация начала памяти

**Пример:**
```
Свободные области: [5 МБ], [8 МБ], [3 МБ], [10 МБ]
Запрос: 4 МБ
Выбор: [5 МБ] (первая подходящая)
Результат: Занято 4 МБ из 5 МБ, остаток 1 МБ остаётся свободным
```

#### 2. Best-fit (наилучший)
**Принцип:**
- Просматривается **весь список** свободных областей
- Выбирается раздел, имеющий **наименьший достаточный размер**
- Цель: минимизировать остаток после выделения

**Преимущества:**
- Оставляет самый **маленький остаток**
- Теоретически более эффективное использование памяти

**Недостатки:**
- **Медленнее** — требует просмотра всего списка
- Может создавать **очень маленькие фрагменты**, которые сложно использовать
- На практике часто **хуже** других методов из-за накопления мелких фрагментов

**Пример:**
```
Свободные области: [5 МБ], [8 МБ], [3 МБ], [10 МБ]
Запрос: 4 МБ
Выбор: [5 МБ] (наименьший подходящий)
Результат: Занято 4 МБ из 5 МБ, остаток 1 МБ
```

#### 3. Worst-fit (наихудший)
**Принцип:**
- Просматривается **весь список** свободных областей
- Выбирается раздел, имеющий **наибольший размер**
- Цель: после размещения процесса остаётся большой свободный фрагмент, который можно использовать

**Преимущества:**
- Оставляет **большие фрагменты**, которые можно использовать для других процессов
- Может быть **лучше Best-fit** в некоторых ситуациях

**Недостатки:**
- **Медленнее** — требует просмотра всего списка
- Быстро **расходует большие блоки** памяти
- Плохо работает при наличии больших процессов

**Пример:**
```
Свободные области: [5 МБ], [8 МБ], [3 МБ], [10 МБ]
Запрос: 4 МБ
Выбор: [10 МБ] (наибольший)
Результат: Занято 4 МБ из 10 МБ, остаток 6 МБ остаётся свободным (большой фрагмент)
```
#### 4. Next-fit (следующий подходящий)
**Принцип:**
- Модификация алгоритма First-fit
- Поиск начинается **не с начала списка**, а **с места, где завершился предыдущий поиск**
- При следующем запросе поиск продолжается с места последнего выделения

**Преимущества:**
- Равномернее распределяет нагрузку по памяти
- Избегает концентрации мелких фрагментов в начале списка
- Немного быстрее First-fit

**Недостатки:**
- Может привести к большей фрагментации
- Сложнее объединение соседних свободных блоков

### Сравнение алгоритмов
**Экспериментальные исследования показали:**
- **First-fit** и **Best-fit** работают **лучше**, чем Worst-fit с точки зрения времени и использования памяти
- **First-fit** обычно **быстрее**, чем Best-fit
- **Best-fit** на практике часто **хуже** First-fit из-за накопления мелких фрагментов
- **Next-fit** может привести к большей фрагментации, чем First-fit

**Рекомендация:**
В большинстве практических случаев наилучшим выбором является **First-fit** как компромисс между скоростью и эффективностью использования памяти.

### Преимущества распределения динамическими разделами
**1. Отсутствие внутренней фрагментации:**
- Процессу выделяется **ровно столько памяти**, сколько ему нужно
- Нет потери памяти внутри разделов (или она незначительна)

**2. Гибкость:**
- Система адаптируется к **размерам процессов**
- Нет жёстких ограничений на количество процессов
- Можно запускать процессы **разных размеров** эффективно

**3. Эффективное использование памяти:**
- При отсутствии фрагментации вся доступная память может быть использована
- Лучше, чем фиксированные разделы для систем с разнообразными процессами

**4. Возможность выполнения больших процессов:**
- Процесс может занимать большую часть памяти
- Нет ограничений фиксированным размером раздела (кроме общего размера памяти)

### Недостатки распределения динамическими разделами
**1. Внешняя фрагментация:**
- Между занятыми блоками памяти остаются **небольшие свободные промежутки**
- Общий объём свободной памяти может быть достаточен, но она **разбросана** по маленьким кускам
- Невозможно выделить большой непрерывный блок памяти

**Иллюстрация внешней фрагментации:**
```
Память после работы нескольких процессов:
┌────────────┐
│  ОС        │
├────────────┤
│ Процесс A  │ 3 МБ
├────────────┤
│ **Дыра**   │ 1 МБ ← Мелкий фрагмент
├────────────┤
│ Процесс B  │ 2 МБ
├────────────┤
│ **Дыра**   │ 0.5 МБ ← Мелкий фрагмент
├────────────┤
│ Процесс C  │ 4 МБ
├────────────┤
│ **Дыра**   │ 2 МБ ← Мелкий фрагмент
└────────────┘

Свободно: 1 + 0.5 + 2 = 3.5 МБ (разбросано)
Запрос процесса D: 3 МБ → **Не может быть выполнен!**
(хотя суммарно свободной памяти достаточно)
```

**2. Правило 50% (статистическая оценка):**
- При распределении памяти блоками произвольного размера **внешняя фрагментация в среднем составляет около половины** выделенной памяти
- Это означает, что примерно **половина памяти** может быть потрачена на мелкие неиспользуемые фрагменты

**3. Сложность управления:**
- Более сложные структуры данных для учёта свободных и занятых областей
- Накладные расходы на поиск подходящего раздела
- Необходимость периодического объединения соседних свободных блоков

**4. Замедление выделения памяти:**
- Поиск подходящего раздела требует **просмотра списка** свободных областей
- При большом количестве фрагментов поиск может быть медленным

**5. Необходимость дефрагментации:**
- Для устранения внешней фрагментации требуется **дефрагментация** (сжатие памяти)
- Дефрагментация — **дорогостоящая операция**

---
## Учёт занятого и свободного пространства
### Структуры данных для учёта памяти
Для эффективного управления памятью операционная система должна вести учёт **свободных** и **занятых** областей памяти. Существует несколько основных способов организации этого учёта.

### 1. Битовые массивы (Bitmap)
**Принцип работы:**
- Память распределяется на **блоки** (от нескольких слов до нескольких килобайт)
- Каждому блоку соответствует **один бит** в битовом массиве
- **Значение 0** — блок **свободен**
- **Значение 1** — блок **занят**

**Структура:**
```
Физическая память:
┌──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐
│Блок 0│Блок 1│Блок 2│Блок 3│Блок 4│Блок 5│Блок 6│Блок 7│
│ ОС   │ПроцА │ПроцА │Своб. │ПроцБ │Своб. │Своб. │ПроцС │
└──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘

Битовый массив:
┌───┬───┬───┬───┬───┬───┬───┬───┐
│ 1 │ 1 │ 1 │ 0 │ 1 │ 0 │ 0 │ 1 │
└───┴───┴───┴───┴───┴───┴───┴───┘
```

**Размер блока — важный параметр:**

**Если блок больше:**
- **Преимущество:** Размер битового массива **меньше**
- **Недостаток:** Возникает **внутренняя фрагментация** (процесс занимает неполный блок)

**Если блок меньше:**
- **Преимущество:** Учёт **точнее**, меньше внутренняя фрагментация
- **Недостаток:** Размер битового массива будет **больше**

**Пример расчёта размера:**
```
Оперативная память: 4 ГБ = 4 294 967 296 байт

Размер блока 4 КБ (4096 байт):
- Количество блоков: 4 ГБ / 4 КБ = 1 048 576 блоков
- Размер битового массива: 1 048 576 бит = 131 072 байт = 128 КБ

Размер блока 64 байт:
- Количество блоков: 4 ГБ / 64 байт = 67 108 864 блоков
- Размер битового массива: 67 108 864 бит = 8 388 608 байт ≈ 8 МБ
```

**Преимущества битовых массивов:**
- **Компактность:** малый расход памяти на структуру данных
- **Простота:** легко реализуется
- **Быстрая проверка состояния** одного блока

**Недостатки битовых массивов:**
- **Проблема поиска последовательных свободных блоков:**
  - Если надо найти **k свободных последовательных блоков** для процесса, поиск может оказаться **замедленным**
  - Необходимо сканировать битовый массив в поиске последовательности нулей
  - Биты блоков могут размещаться в разных словах процессора, что усложняет поиск

- **Внутренняя фрагментация:**
  - При больших блоках возникает потеря памяти

**Применение:**
- Используется в некоторых файловых системах (например, ext2, ext3 в Linux)
- Управление свободными блоками на диске

### 2. Связные списки (Linked Lists)
**Принцип работы:**
- Поддержка **связных списков** свободных и занятых участков памяти
- Каждый сегмент списка представляет собой **свободный участок** или участок, **занятый процессом**

**Структура сегмента списка:**
В каждом сегменте содержится:
1. **Начальный адрес** участка памяти
2. **Длина** (размер) участка
3. **Метка** (тип):
   - **H (Hole)** — свободный участок («дыра»)
   - **P (Process)** — занятый участок (процесс)
1. **Указатель на следующий сегмент**

**Пример структуры:**
```
┌──────┬────────┬──────┬───────┬──────────┐
│ Адрес│ Длина  │ Метка│  PID  │ Указатель│
├──────┼────────┼──────┼───────┼──────────┤
│ 0x00 │ 2 МБ   │  P   │  ОС   │  ────►   │
├──────┼────────┼──────┼───────┼──────────┤
│ 0x02 │ 3 МБ   │  P   │  101  │  ────►   │
├──────┼────────┼──────┼───────┼──────────┤
│ 0x05 │ 1 МБ   │  H   │   —   │  ────►   │
├──────┼────────┼──────┼───────┼──────────┤
│ 0x06 │ 4 МБ   │  P   │  205  │  ────►   │
├──────┼────────┼──────┼───────┼──────────┤
│ 0x0A │ 6 МБ   │  H   │   —   │  NULL    │
└──────┴────────┴──────┴───────┴──────────┘
```

**Сортировка списка:**
Если список **отсортирован по адресам**, управление списком **упрощается**:
- При освобождении памяти **соседние свободные участки** легко обнаружить и **объединить (слить)**
- Список становится **короче** и **эффективнее**

**Процесс объединения соседних свободных участков:**
```
До освобождения процесса B:
┌────┬────┬────┬────┬────┐
│ОС  │ A  │ H1 │ B  │ H2 │
└────┴────┴────┴────┴────┘

После освобождения процесса B:
┌────┬────┬────┬────┬────┐
│ОС  │ A  │ H1 │ H' │ H2 │  ← Три соседние дыры
└────┴────┴────┴────┴────┘

После объединения:
┌────┬────┬──────────────┐
│ОС  │ A  │      H       │  ← Одна большая дыра
└────┴────┴──────────────┘
```

**Варианты организации списков:**
**Вариант 1: Единый список свободных и занятых участков**
- Все участки (свободные и занятые) в **одном списке**
- Различаются по метке (H или P)
- **Преимущество:** простота
- **Недостаток:** при поиске свободного участка приходится просматривать и занятые

**Вариант 2: Отдельные списки**
- **Список свободных участков** (только H)
- **Список занятых участков** (только P)
- **Преимущество:** быстрый поиск свободного участка (просмотр только списка свободных)
- **Недостаток:** сложнее объединять соседние свободные участки

**Вариант 3: Двусвязный список**
- Каждый сегмент имеет указатели на **предыдущий** и **следующий** сегменты
- **Преимущество:** быстрое объединение соседних свободных участков
- **Недостаток:** больший расход памяти на структуру

### Преимущества связных списков
**1. Компактность при малом количестве участков:**
- Если в памяти мало фрагментов, список компактен
- Расход памяти на структуру данных **пропорционален количеству участков**, а не размеру памяти

**2. Быстрое выделение и освобождение:**
- Выделение памяти: поиск подходящего элемента в списке
- Освобождение: удаление из списка занятых, добавление в список свободных, объединение соседних

**3. Поддержка разных размеров участков:**
- Естественным образом поддерживаются участки **произвольного размера**
- Нет внутренней фрагментации (как в битовых массивах с крупными блоками)

**4. Простота реализации алгоритмов First-fit, Best-fit, Worst-fit:**
- Достаточно просмотреть список свободных участков

### Недостатки связных списков
**1. Расход памяти при большой фрагментации:**
- Если память **сильно фрагментирована**, количество элементов списка **велико**
- Значительный расход памяти на хранение структуры данных

**2. Медленный поиск при большой фрагментации:**
- Просмотр длинного списка требует времени
- Линейная сложность поиска: O(n), где n — количество участков

**3. Сложность объединения:**
- При использовании отдельных списков сложнее объединять соседние свободные участки
- Требуется дополнительная информация о соседях

### 3. Другие структуры данных
Помимо битовых массивов и связных списков, существуют и другие структуры данных для учёта памяти:

**Деревья (Binary Search Trees, B-деревья):**
- Ускоряют поиск свободного участка нужного размера
- Сложность поиска: O(log n)
- Используются в некоторых современных системах управления памятью

**Бадди-система (Buddy System):**
- Память делится на блоки размером, являющимся степенью двойки (2ᵏ)
- Упрощает объединение соседних свободных блоков
- Используется в ядре Linux для управления физической памятью

**Сегрегированные списки (Segregated Lists):**
- Отдельные списки для блоков разных размеров
- Ускоряет поиск блока нужного размера
- Используется в некоторых аллокаторах памяти (например, в glibc malloc)

---
## Перемещаемые разделы и сжатие памяти
### Проблема внешней фрагментации при динамических разделах
При распределении памяти **динамическими разделами** фрагментация памяти возникает при **любом алгоритме** выбора подходящего участка:
- В некоторых случаях фрагментация накапливается **быстрее** (например, при Best-fit)
- В некоторых случаях чуть **медленнее** (например, при First-fit)

Но в итоге **внешняя фрагментация неизбежна**.

**Внутренняя фрагментация:**
В случае распределения динамическими разделами внутренняя фрагментация будет **незначительной**, так как процессам выделяется ровно столько памяти, сколько запрошено.

### Операция сжатия памяти (Compaction)
**Определение:**
Для устранения внешней фрагментации применяется операция **сжатия памяти (compaction)** — перемещение занятых блоков памяти так, чтобы они располагались **последовательно**, а вся свободная память объединялась в **один большой непрерывный блок**.

**Механизм:**
1. **Приостановка процессов** (или выполнение во время простоя)
2. **Перемещение** кодов и данных процессов в памяти
3. **Обновление** таблиц адресов и указателей
4. **Объединение** всех свободных участков в один

![[OS 46.png]]

**Пример сжатия памяти:**

**До сжатия:**
```
┌──────────────┐ 0x0000
│  ОС (2 МБ)   │
├──────────────┤ 0x0200
│ Процесс A    │ 3 МБ
│   (3 МБ)     │
├──────────────┤ 0x0500
│ **Дыра 1 МБ**│ ← Внешняя фрагментация
├──────────────┤ 0x0600
│ Процесс B    │ 2 МБ
│   (2 МБ)     │
├──────────────┤ 0x0800
│ **Дыра 2 МБ**│ ← Внешняя фрагментация
├──────────────┤ 0x0A00
│ Процесс C    │ 4 МБ
│   (4 МБ)     │
├──────────────┤ 0x0E00
│ **Дыра 3 МБ**│ ← Внешняя фрагментация
└──────────────┘ 0x1100

Свободно: 1 + 2 + 3 = 6 МБ (разбросано)
Нельзя выделить 6 МБ непрерывно!
```

**После сжатия:**
```
┌──────────────┐ 0x0000
│  ОС (2 МБ)   │
├──────────────┤ 0x0200
│ Процесс A    │ 3 МБ (перемещён)
│   (3 МБ)     │
├──────────────┤ 0x0500
│ Процесс B    │ 2 МБ (перемещён)
│   (2 МБ)     │
├──────────────┤ 0x0700
│ Процесс C    │ 4 МБ (перемещён)
│   (4 МБ)     │
├──────────────┤ 0x0B00
│              │
│  Свободно    │ 6 МБ (один блок)
│   (6 МБ)     │
│              │
└──────────────┘ 0x1100

Свободно: 6 МБ (один непрерывный блок)
Можно выделить до 6 МБ непрерывно!
```

### Требования для реализации сжатия памяти
**1. Перемещаемость кодов процессов:**
- Коды и данные процессов должны быть **перемещаемыми**
- Необходимо использовать **динамическое преобразование адресов**
- **Статическое преобразование** не позволяет перемещать процессы

**2. Аппаратная поддержка:**
- Наличие **MMU** (Memory Management Unit)
- **Базовые регистры** для динамического преобразования адресов
- Поддержка быстрого изменения базовых адресов процессов

**3. Возможность обновления адресов:**
- Необходимо обновить **базовые регистры** всех перемещённых процессов
- Обновить **таблицы страниц** (если используется страничная организация)
- Обновить все **указатели** на перемещённые области

### Стоимость сжатия памяти
**Сжатие памяти — дорогостоящая операция:**

**1. Время выполнения:**
- Необходимо **скопировать большие объёмы данных** в памяти
- Копирование гигабайтов данных может занять **секунды**

**Пример:**
```
Скорость копирования в памяти: ~10 ГБ/с
Объём перемещаемых данных: 4 ГБ
Время сжатия: 4 ГБ / 10 ГБ/с = 0.4 секунды

(Но с учётом накладных расходов — до нескольких секунд)
```

**2. Приостановка процессов:**
- Во время сжатия процессы должны быть **остановлены** или замедлены
- Это приводит к **задержкам** в работе системы
- Неприемлемо для систем реального времени

**3. Накладные расходы на обновление структур:**
- Необходимо обновить **таблицы адресов**
- Обновить **базовые регистры** процессов
- Обновить **таблицы страниц** (если используется страничная организация)
- Сбросить **TLB** (кэш преобразования адресов)

**4. Частота выполнения:**
- Чем чаще выполняется сжатие, тем больше накладные расходы
- Но без сжатия фрагментация приводит к неэффективному использованию памяти

### Стратегии применения сжатия
**1. Периодическое сжатие:**
- Сжатие выполняется **регулярно** через определённые интервалы времени
- Например, каждые N минут или после выполнения M процессов
- **Недостаток:** может выполняться впустую, если фрагментация незначительна

**2. Сжатие по достижению порога:**
- Сжатие выполняется, когда уровень фрагментации достигает определённого **порога**
- Например, когда самый большой свободный блок меньше X% от общей свободной памяти
- **Преимущество:** сжатие выполняется только при необходимости

**3. Сжатие при невозможности выделения памяти:**
- Сжатие выполняется **только** когда не удаётся найти подходящий свободный блок для нового процесса
- **Преимущество:** минимальное количество операций сжатия
- **Недостаток:** задержка при создании процесса

**4. Фоновое сжатие:**
- Сжатие выполняется **в фоновом режиме** в периоды низкой нагрузки
- Используется в некоторых современных ОС
- **Преимущество:** минимальное влияние на производительность

### Альтернативы сжатию памяти
Из-за высокой стоимости операции сжатия современные операционные системы используют **альтернативные методы** управления памятью:

**1. Страничная организация памяти (Paging):**
- Память делится на **страницы фиксированного размера**
- Физическая память делится на **фреймы** (frames)
- **Нет внешней фрагментации** (только незначительная внутренняя)
- Не требуется сжатие

**2. Сегментно-страничная организация:**
- Комбинация сегментов и страниц
- Сегменты делятся на страницы
- Гибкость сегментации + отсутствие фрагментации страничной организации

**3. Виртуальная память:**
- Использование диска как расширения оперативной памяти
- Вытеснение неиспользуемых данных на диск
- Решает проблему недостатка памяти без сжатия

**4. Buddy System (бадди-система):**
- Память выделяется блоками размером 2ᵏ
- Упрощённое объединение соседних свободных блоков
- Меньшая фрагментация, но всё ещё есть внутренняя фрагментация
